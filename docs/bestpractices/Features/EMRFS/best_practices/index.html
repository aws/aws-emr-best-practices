<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-bestpractices/Features/EMRFS/best_practices" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.1.0">
<title data-rh="true">EMRFS - AIMD Retry Strategy for Amazon S3 Requests in EMRFS | AWS Open Data Analytics</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://aws.github.io/aws-emr-best-practices/img/AWS_logo_RGB.png"><meta data-rh="true" name="twitter:image" content="https://aws.github.io/aws-emr-best-practices/img/AWS_logo_RGB.png"><meta data-rh="true" property="og:url" content="https://aws.github.io/aws-emr-best-practices/docs/bestpractices/Features/EMRFS/best_practices"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="EMRFS - AIMD Retry Strategy for Amazon S3 Requests in EMRFS | AWS Open Data Analytics"><meta data-rh="true" name="description" content="Amazon EMR File System (EMRFS) is a feature that allows Amazon EMR clusters to directly access data stored in Amazon S3. However, in large clusters, the high volume of S3 requests can sometimes lead to throttling exceptions from S3. To address this issue, starting with Amazon EMR release 6.4.0, EMRFS supports an alternative retry strategy based on the Additive Increase/Multiplicative Decrease (AIMD) algorithm."><meta data-rh="true" property="og:description" content="Amazon EMR File System (EMRFS) is a feature that allows Amazon EMR clusters to directly access data stored in Amazon S3. However, in large clusters, the high volume of S3 requests can sometimes lead to throttling exceptions from S3. To address this issue, starting with Amazon EMR release 6.4.0, EMRFS supports an alternative retry strategy based on the Additive Increase/Multiplicative Decrease (AIMD) algorithm."><link data-rh="true" rel="icon" href="/aws-emr-best-practices/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://aws.github.io/aws-emr-best-practices/docs/bestpractices/Features/EMRFS/best_practices"><link data-rh="true" rel="alternate" href="https://aws.github.io/aws-emr-best-practices/docs/bestpractices/Features/EMRFS/best_practices" hreflang="en"><link data-rh="true" rel="alternate" href="https://aws.github.io/aws-emr-best-practices/docs/bestpractices/Features/EMRFS/best_practices" hreflang="x-default"><link rel="stylesheet" href="/aws-emr-best-practices/assets/css/styles.7a6c5961.css">
<script src="/aws-emr-best-practices/assets/js/runtime~main.8da87d48.js" defer="defer"></script>
<script src="/aws-emr-best-practices/assets/js/main.d4601c11.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/aws-emr-best-practices/"><div class="navbar__logo"><img src="/aws-emr-best-practices/img/logo.svg" alt="AWS Open Data Analytics" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/aws-emr-best-practices/img/logo.svg" alt="AWS Open Data Analytics" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">AWS Open Data Analytics</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/aws-emr-best-practices/docs/bestpractices/">Best Practices</a><a class="navbar__item navbar__link" href="/aws-emr-best-practices/docs/benchmarks/introduction">Benchmarks</a><a class="navbar__item navbar__link" href="/aws-emr-best-practices/docs/utilities/">Utilities</a><a class="navbar__item navbar__link" href="/aws-emr-best-practices/docs/migration/introduction">Migration</a></div><div class="navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input id="search_input_react" type="search" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/aws-emr-best-practices/docs/bestpractices/">EMR Best Practices Introduction</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/aws-emr-best-practices/docs/bestpractices/Cost Optimizations/Introduction">Cost Optimizations</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/aws-emr-best-practices/docs/bestpractices/Reliability/introduction">Reliability</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/aws-emr-best-practices/docs/bestpractices/Security/introduction">Security</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/aws-emr-best-practices/docs/bestpractices/Features/EMRFS/best_practices">Features</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Features/EMRFS/best_practices">EMRFS</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Features/EMRFS/best_practices">Best Practices</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Features/Managed Scaling/best_practices">Managed Scaling</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Features/Spot Usage/best_practices">Spot Usage</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/aws-emr-best-practices/docs/bestpractices/Applications/Hadoop/introduction">Applications</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/aws-emr-best-practices/docs/bestpractices/Architecture/Adhoc/introduction">Architecture</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/aws-emr-best-practices/docs/bestpractices/Observability/best_practices">Observability</a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/aws-emr-best-practices/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Features</span><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">EMRFS</span><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Best Practices</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>EMRFS - AIMD Retry Strategy for Amazon S3 Requests in EMRFS</h1>
<p>Amazon EMR File System (EMRFS) is a feature that allows Amazon EMR clusters to directly access data stored in Amazon S3. However, in large clusters, the high volume of S3 requests can sometimes lead to throttling exceptions from S3. To address this issue, starting with Amazon EMR release 6.4.0, EMRFS supports an alternative retry strategy based on the Additive Increase/Multiplicative Decrease (AIMD) algorithm.</p>
<p>The AIMD retry strategy is designed to dynamically adjust the request rate to S3 based on the success or failure of recent requests. This approach helps reduce the number of throttled requests and the total number of attempts required per request, ultimately improving the overall performance and efficiency of S3 interactions. The AIMD algorithm works as follows:</p>
<ol>
<li>Additive Increase: When consecutive requests to S3 are successful, the request rate is gradually increased in small increments. This allows EMRFS to probe for available bandwidth without overwhelming S3.</li>
<li>Multiplicative Decrease: If S3 returns a 503 (Slow Down) response, indicating throttling, the request rate is reduced multiplicatively by a larger factor. This rapid reduction helps alleviate congestion and prevent further throttling.</li>
</ol>
<p>By default, the AIMD retry strategy is disabled in EMRFS, as it can potentially degrade performance in some scenarios, especially if other accounts or jobs are causing the high load on the S3 bucket used by the cluster. However, for large Amazon EMR clusters that frequently encounter throttling exceptions, enabling the AIMD retry strategy can significantly improve the overall performance and reliability of S3 interactions.</p>
<p>To enable the AIMD retry strategy, users need to set the fs.s3.aimd.enabled property to true in their emrfs-site configuration. Additionally, EMRFS provides several advanced configuration properties to fine-tune the AIMD behavior, such as <a href="https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-spark-emrfs-retry.html#emr-spark-emrfs-retry-advanced-properties" target="_blank" rel="noopener noreferrer">adjusting the rate of increase and decrease, setting minimum and maximum request rates, and controlling the frequency of rate adjustments.</a></p>
<p>While the AIMD retry strategy may result in slightly lower throughput compared to more aggressive approaches (default <a href="https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-spark-emrfs-retry.html#emr-spark-emrfs-retry-exponential-backoff" target="_blank" rel="noopener noreferrer">exponential backoff strategy</a>), it strikes a balance between achieving reasonable performance and maintaining network stability and fairness. By dynamically adjusting the request rate based on network conditions, AIMD helps prevent congestion collapse and promotes better overall performance for large Amazon EMR clusters heavily interacting with Amazon S3.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="when-to-enable-the-aimd-retry-strategy">When to Enable the AIMD Retry Strategy<a href="#when-to-enable-the-aimd-retry-strategy" class="hash-link" aria-label="Direct link to When to Enable the AIMD Retry Strategy" title="Direct link to When to Enable the AIMD Retry Strategy">​</a></h2>
<p>To determine when to enable the AIMD strategy, we need to first understand the main factors contributing to S3 throttling. Typically, if a single application is generating S3 throttled requests, excluding third-party interactions (other jobs or accounts reading/writing to the bucket), the throttling is primarily driven by the number of concurrent S3 requests generated by each container, which is typically influenced by the number of vCores used in the container.</p>
<p>The number of S3 requests can vary significantly depending on the characteristics of the files being read or written during the job. S3 has different rate limits for different API requests (<a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/optimizing-performance.html" target="_blank" rel="noopener noreferrer">3,500 PUT/COPY/POST/DELETE or 5,500 GET/HEAD requests per second</a>), so certain job phases might be more prone to throttling depending on the operations being performed.</p>
<p>It&#x27;s important to note that bucket <a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/ErrorCodeBilling.html" target="_blank" rel="noopener noreferrer">owners aren&#x27;t billed for HTTP 5XX server error responses</a>, such as HTTP 503 Slow Down errors. From a cost perspective, the advantage of using the AIMD retry strategy can be significant if it can reduce job duration in the event of S3 throttled requests compared to the default exponential backoff retry strategy.</p>
<p>Having discussed the factors contributing to S3 throttling, we can highlight some guidelines that can help determine when to consider enabling the AIMD retry strategy:</p>
<ol>
<li>Large Cluster Size: If you have a cluster with a total number of vCores greater than the S3 request limits (e.g., 4,000 vCores exceeding the 3,500 PUT request limit per second), it is highly likely to generate throttled requests, especially if the data size and shape allow for it.</li>
<li>Write-Intensive Jobs on Medium-Sized Clusters: For write-intensive jobs running on medium-sized clusters (more than 1,500 vCores) that generate a high number of small files (less than 10 MiB), enabling the AIMD strategy may be beneficial.</li>
<li>Significant Throttling: If more than 20% of the total S3 calls generated by a single job are throttled, considering the AIMD retry strategy could be advantageous.</li>
</ol>
<p>Enabling the AIMD strategy can be particularly useful when dealing with large clusters or write-intensive workloads involving numerous small files. In these scenarios, the default exponential backoff strategy may not be efficient in handling the high volume of throttled requests, leading to prolonged job duration.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="when-not-to-enable-the-aimd-retry-strategy">When Not to Enable the AIMD Retry Strategy<a href="#when-not-to-enable-the-aimd-retry-strategy" class="hash-link" aria-label="Direct link to When Not to Enable the AIMD Retry Strategy" title="Direct link to When Not to Enable the AIMD Retry Strategy">​</a></h2>
<p>While the AIMD retry strategy is beneficial for large clusters with dedicated S3 buckets facing severe throttling issues, it may not be necessary or even harmful in certain situations. For smaller clusters, enabling the AIMD retry strategy may degrade performance if the throttled requests are caused by other clusters or applications external to your cluster. In this case, you might end up sacrificing throughput on the small cluster even though it is not the primary cause of the issue.</p>
<p>Besides, overall the AIMD can increase the processing time of a job, thus increasing the overall compute costs, so AIMD should be enabled only whenever required and shouldn&#x27;t be used as a default retry strategy unless strictly required. If the number of throttling events is not significant, the overhead of dynamically adjusting the request rate may outweigh the benefits of reduced throttling. Therefore, it&#x27;s crucial to evaluate the trade-off between improved reliability and potential performance impact before enabling AIMD.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="benchmark">Benchmark<a href="#benchmark" class="hash-link" aria-label="Direct link to Benchmark" title="Direct link to Benchmark">​</a></h2>
<p>For these tests, we used a simple Spark application to read and write an input dataset from S3. We then tuned some Spark configurations to increase the chances of triggering S3 throttled requests using the same job during the write operation. Below is an example of the scripts used to create and submit the Spark jobs:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">script_path=&quot;/tmp/spark-s3-throttle.py&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">input_path=&quot;s3://ripani.dub.tests/store_sales/&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">output_path=&quot;s3://ripani.dub.tests/emrfs_default/&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cat &lt;&lt; EOF &gt; $script_path</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import sys</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from pyspark.sql import SparkSession</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">input_path = sys.argv[1]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">output_path = sys.argv[2]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">spark = SparkSession.builder.getOrCreate()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">df = spark.read.parquet(input_path)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">df.write.mode(&#x27;overwrite&#x27;).parquet(output_path)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">EOF</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>We used various spark-submit commands to trigger the tests with different configurations:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">## standard configurations</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">spark-submit --deploy-mode cluster \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--conf spark.yarn.maxAppAttempts=1 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$script_path $input_path $output_path</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 1M max records per file</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">spark-submit --deploy-mode cluster --conf spark.yarn.maxAppAttempts=1 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--conf spark.sql.files.maxPartitionBytes=&quot;1GB&quot; \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--conf spark.sql.files.maxRecordsPerFile=&quot;1000000&quot; \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$script_path $input_path $output_path</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 500k max records per file</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">spark-submit --deploy-mode cluster \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--conf spark.yarn.maxAppAttempts=1 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--conf spark.sql.files.maxPartitionBytes=&quot;1GB&quot; \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--conf spark.sql.files.maxRecordsPerFile=&quot;500000&quot; \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$script_path $input_path $output_path</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 250k max records per file</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">spark-submit --deploy-mode cluster \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--conf spark.yarn.maxAppAttempts=1 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--conf spark.sql.files.maxPartitionBytes=&quot;1GB&quot; \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--conf spark.sql.files.maxRecordsPerFile=&quot;250000&quot; \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$script_path $input_path $output_path</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 100k max records per file</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">spark-submit --deploy-mode cluster \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--conf spark.yarn.maxAppAttempts=1 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--conf spark.sql.files.maxPartitionBytes=&quot;1GB&quot; \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--conf spark.sql.files.maxRecordsPerFile=&quot;100000&quot; \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$script_path $input_path $output_path</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>To run the tests, we used a 200 m5d.2xlarge EMR cluster (for a total of 1600 vCores) running emr-7.1.0. As evident from the Python script, we wrote all the data to a single bucket prefix with no partitioning to increase the chances of throttled requests during write operations.</p>
<p>Below a table summarizing data collected during the tests:
<img loading="lazy" src="/aws-emr-best-practices/assets/images/table-bfca38827dc50bd79c64d4194ccad659.png" width="2264" height="384" class="img_ev3q">
The benchmark tested different configurations of spark.sql.files.maxPartitionBytes and spark.sql.files.maxRecordsPerFile to produce various output file shapes and sizes, ranging from a standard 133 MiB files per partition up to 579,158 small 5.2 MiB files. The input dataset consisted of 1486 files totaling 2.7 TiB of compressed parquet data.</p>
<p>Across these workloads, enabling the AIMD retry strategy provided substantial benefits in reducing S3 throttling and improving job duration when throttling was a major bottleneck:</p>
<ul>
<li>For the most throttling-prone case writing 579,158 small 5.2 MiB files (row 9), the default strategy experienced 23.5% throttled S3 requests. With AIMD (row 10), this dropped to just 0.56% while decreasing runtime by 11.6%.</li>
<li>Writing 232,594 small 12.6 MiB files (rows 7-8), AIMD reduced throttling from 14.6% to 0.67, but  improved runtime by 10.4%.</li>
<li>Similar to the previous entry in rows 5-6, AIMD cut throttling from 14.62% to 0.67% but increased of a 29% the overall job runtime.</li>
</ul>
<p>The results demonstrate AIMD&#x27;s effectiveness at mitigating severe throttling scenarios caused by highly parallel, write-intensive workloads on large EMR clusters. While providing substantial reliability and performance gains in these cases, AIMD can slightly degrade performance when throttling pressure is low. For the above reasons, we recommend to benchmark your cluster before enabling the AIMD retry strategy in a production job, if costs is your main concerns.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="analyzing-job-s3-requests-and-throttling">Analyzing Job S3 Requests and Throttling<a href="#analyzing-job-s3-requests-and-throttling" class="hash-link" aria-label="Direct link to Analyzing Job S3 Requests and Throttling" title="Direct link to Analyzing Job S3 Requests and Throttling">​</a></h2>
<p>To analyze the S3 requests generated by an EMR job, you can choose from the methods listed in the Logging options for Amazon S3 available in the AWS Documentation (<a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/logging-with-S3.html" target="_blank" rel="noopener noreferrer">https://docs.aws.amazon.com/AmazonS3/latest/userguide/logging-with-S3.html</a>). Please note that Logging Amazon S3 API calls using AWS CloudTrail can deliver the logs faster in the S3 bucket for analysis (around 5 minutes) but has some additional costs.</p>
<p>To analyze the S3 request logs, you can follow these steps:</p>
<ol>
<li>Enable S3 logging the S3 buckets used by your cluster (<a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/enable-cloudtrail-logging-for-s3.html" target="_blank" rel="noopener noreferrer">https://docs.aws.amazon.com/AmazonS3/latest/userguide/enable-cloudtrail-logging-for-s3.html</a>)</li>
<li>Create a CloudTrail Athena Table to analyze the S3 requests using SQL queries (<a href="https://docs.aws.amazon.com/athena/latest/ug/cloudtrail-logs.html#create-cloudtrail-table-partition-projection" target="_blank" rel="noopener noreferrer">https://docs.aws.amazon.com/athena/latest/ug/cloudtrail-logs.html#create-cloudtrail-table-partition-projection</a>)</li>
<li>Query the data.</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="s3-request--counts">S3 Request / Counts<a href="#s3-request--counts" class="hash-link" aria-label="Direct link to S3 Request / Counts" title="Direct link to S3 Request / Counts">​</a></h2>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">-- Get S3 Requests counts by S3 API name</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">WITH app AS (</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  SELECT</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    date_parse(&#x27;2024-06-04T14:39:56Z&#x27;, &#x27;%Y-%m-%dT%H:%i:%sZ&#x27;) AS start_time,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    date_parse(&#x27;2024-06-04T14:58:54Z&#x27;, &#x27;%Y-%m-%dT%H:%i:%sZ&#x27;) AS end_time,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &#x27;arn:aws:iam::YOUR_ACCOUNT_ID:role/EMR_EC2_DefaultRole&#x27; AS ec2_role</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">SELECT</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  eventname,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  count(*) AS request_count</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">FROM &quot;SCHEMA&quot;.&quot;YOUR_CT_TABLE_NAME&quot;, app</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">WHERE date_parse(eventtime, &#x27;%Y-%m-%dT%H:%i:%sZ&#x27;) &gt;= app.start_time</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  AND date_parse(eventtime, &#x27;%Y-%m-%dT%H:%i:%sZ&#x27;) &lt; app.end_time</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  AND useridentity.sessioncontext.sessionissuer.arn = app.ec2_role</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">GROUP BY eventname</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ORDER BY request_count DESC;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-- Get S3 Throttled Requests counts by S3 API name</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">WITH app AS (</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  SELECT</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    date_parse(&#x27;2024-06-04T14:39:56Z&#x27;, &#x27;%Y-%m-%dT%H:%i:%sZ&#x27;) AS start_time,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    date_parse(&#x27;2024-06-04T14:58:54Z&#x27;, &#x27;%Y-%m-%dT%H:%i:%sZ&#x27;) AS end_time,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &#x27;arn:aws:iam::YOUR_ACCOUNT_ID:role/EMR_EC2_DefaultRole&#x27; AS ec2_role</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">SELECT</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  eventname,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  count(*) AS request_count</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">FROM &quot;SCHEMA&quot;.&quot;YOUR_CT_TABLE_NAME&quot;, app</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">WHERE date_parse(eventtime, &#x27;%Y-%m-%dT%H:%i:%sZ&#x27;) &gt;= app.start_time</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  AND date_parse(eventtime, &#x27;%Y-%m-%dT%H:%i:%sZ&#x27;) &lt; app.end_time</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  AND useridentity.sessioncontext.sessionissuer.arn = app.ec2_role</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  AND errorcode = &#x27;SlowDown&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">GROUP BY eventname</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ORDER BY request_count DESC;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>These SQL queries are designed to analyze S3 requests and throttled requests from CloudTrail logs stored in an Athena table. Here&#x27;s a breakdown of what each query does:</p>
<ul>
<li>Get S3 Requests counts by S3 API name:<!-- -->
<ul>
<li>This query retrieves the count of S3 events or API calls grouped by the eventname (which represents the S3 API operation name).</li>
<li>It filters the events based on the following conditions:<!-- -->
<ul>
<li>eventtime (the time when the event occurred) falls within a specific time range defined by the date_parse functions.</li>
<li>useridentity.sessioncontext.sessionissuer.arn matches the provided IAM role ARN used as EC2 Instance Role by the cluster analyzed (in this case, &#x27;arn:aws:iam::YOUR_ACCOUNT_ID<!-- -->:role<!-- -->/EMR_EC2_DefaultRole&#x27;).</li>
</ul>
</li>
<li>The GROUP BY eventname clause groups the results by the S3 API operation name, allowing you to see the count of requests for each operation.</li>
</ul>
</li>
<li>Get S3 Throttled Requests counts by S3 API name:<!-- -->
<ul>
<li>This query is similar to the first one, but it specifically looks for throttled or rate-limited S3 requests by adding an additional filter condition: errorcode = &#x27;SlowDown&#x27;.</li>
<li>The SlowDown error code indicates that the request was throttled due to excessive rates.</li>
<li>Like the previous query, it groups the results by the eventname (S3 API operation name) and counts the number of throttled requests for each operation.</li>
</ul>
</li>
</ul>
<p>Both queries use the Athena table specified by &quot;SCHEMA&quot;.&quot;YOUR_CT_TABLE_NAME&quot;, which should be replaced with the actual schema and table name where your CloudTrail logs are stored.</p>
<p>Additionally, you need to replace &#x27;YOUR_ACCOUNT_ID&#x27; with your actual AWS account ID in the IAM role ARN.</p>
<p>These queries can help you analyze S3 usage patterns, identify frequently used S3 API, and detect potential bottlenecks or performance issues caused by throttled requests. By adjusting the time range and filtering conditions, you can analyze the data for different periods or specific roles/resources as needed.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="s3-requests-visualization">S3 requests visualization<a href="#s3-requests-visualization" class="hash-link" aria-label="Direct link to S3 requests visualization" title="Direct link to S3 requests visualization">​</a></h2>
<p>The following queries are designed to extract data points from AWS CloudTrail logs, which can be used to generate visualizations and dashboards for monitoring and analyzing S3 requests made by a job running on EMR. By aggregating the request counts per second, you can gain insights into the patterns and potential bottlenecks in S3 access during the execution of an EMR job.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">-- Get S3 request count aggregated per second</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">WITH app AS (</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  SELECT</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    date_parse(&#x27;2024-06-04T14:39:56Z&#x27;, &#x27;%Y-%m-%dT%H:%i:%sZ&#x27;) AS start_time,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    date_parse(&#x27;2024-06-04T14:58:54Z&#x27;, &#x27;%Y-%m-%dT%H:%i:%sZ&#x27;) AS end_time,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &#x27;arn:aws:iam::YOUR_ACCOUNT_ID:role/EMR_EC2_DefaultRole&#x27; AS ec2_role</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">SELECT</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  eventtime,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  count(*) AS request_count</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">FROM &quot;SCHEMA&quot;.&quot;YOUR_CT_TABLE_NAME&quot;, app</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">WHERE date_parse(eventtime, &#x27;%Y-%m-%dT%H:%i:%sZ&#x27;) &gt;= app.start_time</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  AND date_parse(eventtime, &#x27;%Y-%m-%dT%H:%i:%sZ&#x27;) &lt; app.end_time</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  AND useridentity.sessioncontext.sessionissuer.arn = app.ec2_role</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">GROUP BY eventtime</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ORDER BY eventtime;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-- Get S3 throttled request count aggregated per second</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">WITH app AS (</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  SELECT</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    date_parse(&#x27;2024-06-04T14:39:56Z&#x27;, &#x27;%Y-%m-%dT%H:%i:%sZ&#x27;) AS start_time,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    date_parse(&#x27;2024-06-04T14:58:54Z&#x27;, &#x27;%Y-%m-%dT%H:%i:%sZ&#x27;) AS end_time,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &#x27;arn:aws:iam::YOUR_ACCOUNT_ID:role/EMR_EC2_DefaultRole&#x27; AS ec2_role</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">SELECT</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  eventtime,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  count(*) AS request_count</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">FROM &quot;SCHEMA&quot;.&quot;YOUR_CT_TABLE_NAME&quot;, app</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">WHERE date_parse(eventtime, &#x27;%Y-%m-%dT%H:%i:%sZ&#x27;) &gt;= app.start_time</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  AND date_parse(eventtime, &#x27;%Y-%m-%dT%H:%i:%sZ&#x27;) &lt; app.end_time</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  AND useridentity.sessioncontext.sessionissuer.arn = app.ec2_role</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  AND errorcode = &#x27;SlowDown&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">GROUP BY eventtime</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ORDER BY eventtime;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>The first query retrieves the total count of S3 requests made by the EMR cluster within a specific time range, grouped by the event time (aggregated by second). This data can be used to create a line chart or time-series visualization, showing the overall S3 request volume over time.</p>
<p>The second query focuses specifically on throttled S3 requests, where the error code &#x27;SlowDown&#x27; was encountered. This query provides insights into periods when the EMR cluster experienced S3 throttling, which can occur when the request rate exceeds the service limits imposed by Amazon S3. By visualizing the throttled request counts over time, you can identify potential bottlenecks and take steps to adjust the S3 access patterns .</p>
<p>To illustrate a practical example, consider the following visualization that depicts the behavior of job runs 9 and 10, highlighting the difference in how the respective EMRFS retry algorithms react to throttling events.
<img loading="lazy" src="/aws-emr-best-practices/assets/images/pic1-2dfa4e87cb2574dec10cc9b8be02658b.png" width="2934" height="996" class="img_ev3q">
Figure 1. Exponential Backoff
<img loading="lazy" src="/aws-emr-best-practices/assets/images/pic2-773aa65933355a77c2786272e529d601.png" width="2934" height="996" class="img_ev3q">
Figure 2. AIMD Retry</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="alternative-approach---s3-analysis-using-yarn-container-logs">Alternative Approach - S3 analysis using YARN Container Logs<a href="#alternative-approach---s3-analysis-using-yarn-container-logs" class="hash-link" aria-label="Direct link to Alternative Approach - S3 analysis using YARN Container Logs" title="Direct link to Alternative Approach - S3 analysis using YARN Container Logs">​</a></h2>
<p>As an alternative approach, you can enable Spark Debug Logs when launching an EMR cluster to include S3 call details in the YARN container logs. This can be achieved by setting the Spark rootLogger.level to debug and the logger.http.level to off in the spark-log4j2 classification.</p>
<p>After running your Spark job, you can use the provided spark_s3_analyze.sh script to analyze the YARN container logs and retrieve various S3 metrics. The script downloads and decompresses the logs, calculates the application&#x27;s elapsed time, counts the S3 requests by type, lists the input and output S3 paths with their sizes and displays the top 10 S3 requests per second.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="emr-cluster-classification">EMR Cluster Classification<a href="#emr-cluster-classification" class="hash-link" aria-label="Direct link to EMR Cluster Classification" title="Direct link to EMR Cluster Classification">​</a></h2>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">[</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;Classification&quot;: &quot;spark&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;Properties&quot;: {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      &quot;maximizeResourceAllocation&quot;: &quot;true&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;Classification&quot;: &quot;spark-log4j2&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;Properties&quot;: {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      &quot;rootLogger.level&quot;: &quot;debug&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      &quot;logger.http.name&quot;: &quot;com.amazon.ws.emr.hadoop.fs.shaded.org.apache.http.wire&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      &quot;logger.http.level&quot;: &quot;off&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="spark_s3_analyzesh---script-to-analyze-yarn-container-logs-for-s3-details">spark_s3_analyze.sh - Script to analyze YARN Container logs for S3 details<a href="#spark_s3_analyzesh---script-to-analyze-yarn-container-logs-for-s3-details" class="hash-link" aria-label="Direct link to spark_s3_analyze.sh - Script to analyze YARN Container logs for S3 details" title="Direct link to spark_s3_analyze.sh - Script to analyze YARN Container logs for S3 details">​</a></h2>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">#!/bin/bash</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#===============================================================================</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#!# script: spark_s3_analyze.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#!# version: v0.1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#!#</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#!# Process Spark (YARN container&#x27;s logs) to retrieve S3 metrics</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#===============================================================================</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#?#</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#?# usage: ./spark_s3_analyze.sh &lt;S3_LOG&gt; &lt;S3_INPUT&gt; &lt;S3_OUTPUT&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#?#</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#?#   S3_LOG              Amazon EMR S3 Log Path</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#?#   S3_INPUT            S3 path of the input data</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#?#   S3_OUTPUT           S3 path of the output data</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#?#</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#===============================================================================</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">RED=&#x27;\033[0;31m&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NC=&#x27;\033[0m&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">s3_logs=&quot;$1&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">input_path=&quot;$2&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">output_path=&quot;$3&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># dowload and decompress logs</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tmp_path=$(mktemp -d)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd $tmp_path &amp;&amp; aws s3 sync $s3_logs . </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">gzip -d */*.gz</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">echo -e &quot;# ${RED}Application Time${NC}\n&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">completed=$(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  grep -Ri &quot;Final app status&quot; *001/stderr | awk &#x27;{split($0,a,&quot; &quot;); print a[2]}&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">started=$(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  grep -Ri &quot;ApplicationAttemptId:&quot; *001/stderr | awk &#x27;{split($0,a,&quot; &quot;); print a[2]}&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">start=$(echo $started | awk -F: &#x27;{ print ($1 * 3600) + ($2 * 60) + $3 }&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">end=$(echo $completed | awk -F: &#x27;{ print ($1 * 3600) + ($2 * 60) + $3 }&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">duration=$(($end - $start))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">elapsed=$(TZ=UTC0 printf &#x27;%(%H:%M:%S)T\n&#x27; $duration)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">echo &quot;Started   : $started&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">echo &quot;Completed : $completed&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">echo &quot;Elapsed   : $elapsed ($duration sec)&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">echo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">echo -e &quot;# ${RED}Get S3 requests count${NC}\n&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">grep -Rh &quot;Executing request&quot; * | awk &#x27;{split($0,a,&quot; &quot;); print a[7]}&#x27; | \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  sort | uniq -c</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">echo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">echo -e &quot;# ${RED}S3 Input Path${NC}\n&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">echo -e &quot;Path: $input_path\n&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">aws s3 ls $input_path --recursive --summarize --human-readable | grep &quot;Total&quot; | \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  sed &#x27;s/^ *//; s/ *$//; /^$/d&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">echo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">echo -e &quot;# ${RED}S3 Output Path${NC}\n&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">echo -e &quot;Path: $output_path\n&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">aws s3 ls $output_path --recursive --summarize --human-readable | grep &quot;Total&quot; | \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  sed &#x27;s/^ *//; s/ *$//; /^$/d&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">echo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">echo -e &quot;# ${RED}S3 Requests x second (${NC}Top 10${RED})${NC}\n&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">grep -Rh &quot;Executing request&quot; * | awk &#x27;{split($0,a,&quot; &quot;); print a[2]}&#x27; | \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  sort | uniq -c | sort -n | tail -n 10</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">rm -rf $tmp_path</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/bestpractices/4 - Features/EMRFS/best_practices.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/aws-emr-best-practices/docs/bestpractices/Security/best_practices"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Best Practices</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/aws-emr-best-practices/docs/bestpractices/Features/Managed Scaling/best_practices"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Best Practices</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#when-to-enable-the-aimd-retry-strategy" class="table-of-contents__link toc-highlight">When to Enable the AIMD Retry Strategy</a></li><li><a href="#when-not-to-enable-the-aimd-retry-strategy" class="table-of-contents__link toc-highlight">When Not to Enable the AIMD Retry Strategy</a></li><li><a href="#benchmark" class="table-of-contents__link toc-highlight">Benchmark</a></li><li><a href="#analyzing-job-s3-requests-and-throttling" class="table-of-contents__link toc-highlight">Analyzing Job S3 Requests and Throttling</a></li><li><a href="#s3-request--counts" class="table-of-contents__link toc-highlight">S3 Request / Counts</a></li><li><a href="#s3-requests-visualization" class="table-of-contents__link toc-highlight">S3 requests visualization</a></li><li><a href="#alternative-approach---s3-analysis-using-yarn-container-logs" class="table-of-contents__link toc-highlight">Alternative Approach - S3 analysis using YARN Container Logs</a></li><li><a href="#emr-cluster-classification" class="table-of-contents__link toc-highlight">EMR Cluster Classification</a></li><li><a href="#spark_s3_analyzesh---script-to-analyze-yarn-container-logs-for-s3-details" class="table-of-contents__link toc-highlight">spark_s3_analyze.sh - Script to analyze YARN Container logs for S3 details</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Get Involved</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/aws/aws-emr-best-practices/tree/main" target="_blank" rel="noopener noreferrer" class="footer__link-item">Github<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Built with ❤️ at AWS  <br> © 2024 Amazon.com, Inc. or its affiliates. All Rights Reserved</div></div></div></footer></div>
</body>
</html>