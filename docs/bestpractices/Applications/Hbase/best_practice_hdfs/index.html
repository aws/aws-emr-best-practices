<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-bestpractices/Applications/Hbase/best_practice_hdfs" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.1.0">
<title data-rh="true">Best Practice for HDFS | AWS Open Data Analytics</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://aws.github.io/aws-open-data-analytics/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://aws.github.io/aws-open-data-analytics/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://aws.github.io/aws-open-data-analytics/docs/bestpractices/Applications/Hbase/best_practice_hdfs"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Best Practice for HDFS | AWS Open Data Analytics"><meta data-rh="true" name="description" content="This section highlights some of the features / best practice that you could use to improve the performance in your cluster when using HDFS as storage layer for HBase."><meta data-rh="true" property="og:description" content="This section highlights some of the features / best practice that you could use to improve the performance in your cluster when using HDFS as storage layer for HBase."><link data-rh="true" rel="icon" href="/aws-open-data-analytics/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://aws.github.io/aws-open-data-analytics/docs/bestpractices/Applications/Hbase/best_practice_hdfs"><link data-rh="true" rel="alternate" href="https://aws.github.io/aws-open-data-analytics/docs/bestpractices/Applications/Hbase/best_practice_hdfs" hreflang="en"><link data-rh="true" rel="alternate" href="https://aws.github.io/aws-open-data-analytics/docs/bestpractices/Applications/Hbase/best_practice_hdfs" hreflang="x-default"><link rel="stylesheet" href="/aws-open-data-analytics/assets/css/styles.a4bba1a8.css">
<script src="/aws-open-data-analytics/assets/js/runtime~main.eea7bfcb.js" defer="defer"></script>
<script src="/aws-open-data-analytics/assets/js/main.b4c89324.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/aws-open-data-analytics/"><div class="navbar__logo"><img src="/aws-open-data-analytics/img/logo.svg" alt="AWS Open Data Analytic" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/aws-open-data-analytics/img/logo.svg" alt="AWS Open Data Analytic" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">AWS Open Data Analytics</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/aws-open-data-analytics/docs/bestpractices/">Best Practices</a><a class="navbar__item navbar__link" href="/aws-open-data-analytics/docs/benchmarks/introduction">Benchmarks</a><a class="navbar__item navbar__link" href="/aws-open-data-analytics/docs/utilities/">Utilities</a></div><div class="navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/aws-open-data-analytics/docs/bestpractices/">EMR Best Practices Introduction</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/aws-open-data-analytics/docs/bestpractices/Cost Optimizations/Introduction">Cost Optimizations</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/aws-open-data-analytics/docs/bestpractices/Reliability/introduction">Reliability</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/aws-open-data-analytics/docs/bestpractices/Security/introduction">Security</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/aws-open-data-analytics/docs/bestpractices/Features/Managed Scaling/best_practices">Features</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/aws-open-data-analytics/docs/bestpractices/Applications/Hbase/introduction">Applications</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/aws-open-data-analytics/docs/bestpractices/Applications/Hbase/introduction">Hbase</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/aws-open-data-analytics/docs/bestpractices/Applications/Hbase/introduction">Introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/aws-open-data-analytics/docs/bestpractices/Applications/Hbase/best_practice">Best Practices</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/aws-open-data-analytics/docs/bestpractices/Applications/Hbase/best_practice_hdfs">Best Practice for HDFS</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/aws-open-data-analytics/docs/bestpractices/Applications/Hbase/best_practice_s3">Best Practice for Amazon S3</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/aws-open-data-analytics/docs/bestpractices/Applications/Hbase/data_integrity">Data Integrity / Disaster Recovery / High Availability</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/aws-open-data-analytics/docs/bestpractices/Applications/Hbase/data_migration">Data Migration</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/aws-open-data-analytics/docs/bestpractices/Applications/Hbase/management">Management</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/aws-open-data-analytics/docs/bestpractices/Applications/Hbase/observability">Observability</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/aws-open-data-analytics/docs/bestpractices/Applications/Hbase/performance_tests">Performance Tests</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/aws-open-data-analytics/docs/bestpractices/Applications/Hbase/security">Security</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/aws-open-data-analytics/docs/bestpractices/Applications/Hive/introduction">Hive</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/aws-open-data-analytics/docs/bestpractices/Applications/Spark/introduction">Spark</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/aws-open-data-analytics/docs/bestpractices/Architecture/Adhoc/introduction">Architecture</a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/aws-open-data-analytics/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Applications</span><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Hbase</span><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Best Practice for HDFS</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Best Practice for HDFS</h1>
<p>This section highlights some of the features / best practice that you could use to improve the performance in your cluster when using HDFS as storage layer for HBase.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="hdfs---name-node-memory">HDFS - Name Node memory<a href="#hdfs---name-node-memory" class="hash-link" aria-label="Direct link to HDFS - Name Node memory" title="Direct link to HDFS - Name Node memory">​</a></h2>
<p>When handling large cluster deployments, it’s important to properly size the HDFS NameNode (NN) heap memory which Amazon EMR set accordingly to the <a href="https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-hadoop-daemons.html" target="_blank" rel="noopener noreferrer">instance used</a>. The NN keeps in memory metadata for each file / block allocated in the HDFS, so it’s important to properly size the memory to prevent failures that might create down-times in our services.</p>
<p>To size the NN memory, we can consider that each HDFS block persisted in memory uses approximately 150 bytes. Using this value as reference, you can do a rough estimate of the memory required to store data in the HDFS, considering that a block is 128MB (please note that a file smaller than the HDFS block size will still count as a individual block in memory). As alternative, you can use a rule of thumb and specify 1GB of memory each 1 million blocks stored in the HDFS.</p>
<p>To change the default NN memory, you can use the following <a href="https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-configure-apps.html" target="_blank" rel="noopener noreferrer">EMR Configuration</a>:</p>
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">[</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;Classification&quot;: &quot;hadoop-env&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;Configurations&quot;: [</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;Classification&quot;: &quot;export&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;Properties&quot;: {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          &quot;HADOOP_NAMENODE_HEAPSIZE&quot;: &quot;8192&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;Properties&quot;: {}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="hdfs---service-threads">HDFS - Service Threads<a href="#hdfs---service-threads" class="hash-link" aria-label="Direct link to HDFS - Service Threads" title="Direct link to HDFS - Service Threads">​</a></h2>
<p>Amazon EMR already configures most of the HDFS parameters that are required to get good HDFS performance for HBase. However, if you’re using a large instance with several vCpu, you might benefit in increasing the number of service threads that are available for the HDFS DataNode service. Please note that if you’re using <a href="#hdfs-short-circuit-reads">HDFS - Short Circuit Reads</a> you might not get any additional benefits from this parameter tuning, but this might still be handy if your HDFS is used by other applications.</p>
<p>In this case, setting the <em><code>dfs.datanode.handler.count</code></em> to 3 times the number of vCpu available on the node can be a good starting point. In the same way we can also tune the number of <em><code>dfs.namenode.handler.count</code></em> for larger cluster installations. For this last parameter, you can use the following formula to determine a good value for your cluster</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">20 * log2(number of CORE nodes)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Please note that this value might be useful to increase, if you have more than 20 CORE nodes provisioned in the cluster, otherwise you might stick to the default values set by the service. Also for both <em><code>dfs.namenode.handler.count</code></em> and <em><code>dfs.datanode.handler.count</code></em> you should not set a value higher than 200.</p>
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">[</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;Classification&quot;: &quot;hdfs-site&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;Properties&quot;: {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      &quot;dfs.namenode.handler.count&quot;: &quot;64&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      &quot;dfs.datanode.handler.count&quot;: &quot;48&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="hdfs---short-circuit-reads">HDFS - Short Circuit Reads<a href="#hdfs---short-circuit-reads" class="hash-link" aria-label="Direct link to HDFS - Short Circuit Reads" title="Direct link to HDFS - Short Circuit Reads">​</a></h2>
<p>In HDFS, reads normally go through the Data Node service. When the client asks the Data Node to read a file, the service reads that file off of the disk and sends the data to the client over a TCP socket. The &quot;short-circuit reads&quot; bypass the Data Node, allowing the client to read the file directly. This is only possible in cases where the client is co-located with the data.</p>
<p>The following configurations allow HBase to directly read store files on the local node bypassing the HDFS service providing better performance while accessing data not cached.</p>
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">[</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;Classification&quot;: &quot;hdfs-site&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;Properties&quot;: {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      &quot;dfs.client.read.shortcircuit&quot;: &quot;true&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      &quot;dfs.client.socket-timeout&quot;: &quot;60000&quot;, </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      &quot;dfs.domain.socket.path&quot;: &quot;/var/run/hadoop-hdfs/dn_socket&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>For additional details, see <a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/ShortCircuitLocalReads.html" target="_blank" rel="noopener noreferrer">HDFS Short-Circuit Local Reads</a></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="hdfs---replication-factor">HDFS - Replication Factor<a href="#hdfs---replication-factor" class="hash-link" aria-label="Direct link to HDFS - Replication Factor" title="Direct link to HDFS - Replication Factor">​</a></h2>
<p>As best practice is recommended to launch the EMR cluster using at least 4 CORE nodes. When you launch an EMR cluster with at least 4 CORE nodes, the default HDFS replication factor will be automatically set to 2 by the EMR service. This prevents to lose data in case some CORE nodes get terminated. Please note that you cannot recover a HDFS block if all its replicas are lost (e.g. all CORE nodes containing a specific HDFS block and its replica are terminated). If you want a stronger guarantee about the availability of your data, launch the EMR cluster with at least 10 CORE nodes (this will set the default replication factor to 3), or manually specify the HDFS replication factor using the EMR Configuration API.</p>
<p>If you specify the HDFS replication manually, please make sure to have a sufficient number of CORE nodes to allocate all the replica of your data. For more details see <a href="https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-hdfs-config.html" target="_blank" rel="noopener noreferrer">HDFS configuration</a> in the Amazon EMR documentation.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="hbase---hedged-reads">HBase - Hedged Reads<a href="#hbase---hedged-reads" class="hash-link" aria-label="Direct link to HBase - Hedged Reads" title="Direct link to HBase - Hedged Reads">​</a></h2>
<p>Hadoop 2.4 introduced a new feature called Hedged Reads. If a read from a block is slow, the HDFS client starts up another parallel read against a different block replica. The result of whichever read returns first is used, and the outstanding read is cancelled. This feature helps in situations where a read occasionally takes a long time rather than when there is a systemic problem. Hedged reads can be enabled for HBase when the HFiles are stored in HDFS. This feature is disabled by default.</p>
<p>To enable hedged reads, set <em><code>dfs.client.hedged.read.threadpool.size</code></em> to the number of threads to dedicate to running hedged threads, and <em><code>dfs.client.hedged.read.threshold.millis</code></em> to the number of milliseconds to wait before starting another read against a different block replica.</p>
<p>The following is an example configuration to enable hedged reads using EMR Configurations:</p>
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">[</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;Classification&quot;: &quot;hdfs-site&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;Properties&quot;: {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      &quot;dfs.client.hedged.read.threadpool.size&quot;: &quot;20&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      &quot;dfs.client.hedged.read.threshold.millis&quot;: &quot;100&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="hbase---tiered-storage">HBase - Tiered Storage<a href="#hbase---tiered-storage" class="hash-link" aria-label="Direct link to HBase - Tiered Storage" title="Direct link to HBase - Tiered Storage">​</a></h2>
<p>HBase can take advantage of the <a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/ArchivalStorage.html" target="_blank" rel="noopener noreferrer">Heterogeneous Storage and Archival Storage</a> feature available in the HDFS to store more efficiently data in different type of storage and provide better performance.</p>
<p>One of the use case where this setup might be useful, is for write intensive clusters that have a high ingestion rate and trigger a lot of internal compaction operations. In this case we can define a policy to store HBase WALs on SSD disks present in our nodes (NVMe instance store volumes), while storing HFiles on additional EBS volumes attached to our instances. Please note that this is an advanced configuration that requires additional steps to be enabled on an EMR cluster and might not be beneficial for small clusters with simple ingestion patterns.</p>
<p>Amazon EMR automatically configures both instances volumes stores and EBS disks that are defined while launching the cluster. However, we need to label the volumes attached to our node to specify the corresponding Storage Type for the  corresponding volume.</p>
<p>The first step is to attach a <a href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-bootstrap.html" target="_blank" rel="noopener noreferrer">Bootstrap Action</a> while launching the cluster to label NVMe disks. You can use the following script to label as <strong>SSD</strong> the NVMe disks attached to the cluster&#x27;s nodes.</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">#!/bin/bash</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#===============================================================================</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#!# script: emr-ba-disk_labels.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#!# version: v0.1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#!#</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#!# This Bootstrap Action can be attached to an EMR Cluster to automatically</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#!# tag NVMe Disks using the HDFS Storage Type SSD.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#!#</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#===============================================================================</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#?#</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#?# usage: ./emr-ba-disk_labels.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#?#</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#===============================================================================</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Force the script to run as root</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">if [ $(id -u) != &quot;0&quot; ]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">then</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    sudo &quot;$0&quot; &quot;$@&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    exit $?</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">fi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">## Install nvme-cli</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">yum install -y nvme-cli</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd /tmp &amp;&amp; wget -O epel.rpm –nv https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">yum install -y ./epel.rpm &amp;&amp; yum -y install xmlstarlet</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">## List NVMe disks</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">nvme_disks=($(nvme list | grep &quot;Amazon EC2 NVMe Instance Storage&quot; | awk -F&#x27;[[:space:]][[:space:]]+&#x27; &#x27;{print $1}&#x27;))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">## If there&#x27;s no nvme exit</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[[ ${#nvme_disks[@]} -eq 0 ]] &amp;&amp; echo &quot;No EC2 NVMe Instance Storage found. End script...&quot; &amp;&amp; exit 0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">SCRIPT_NAME=&quot;/tmp/disk_labels.sh&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cat &lt;&lt; &#x27;EOF&#x27; &gt; $SCRIPT_NAME</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#!/bin/bash</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># retrieve dfs.data.dir value</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">HDFS_CORE_SITE=&quot;/etc/hadoop/conf/hdfs-site.xml&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">nvme_disks=($(nvme list | grep &quot;Amazon EC2 NVMe Instance Storage&quot; | awk -F&#x27;[[:space:]][[:space:]]+&#x27; &#x27;{print $1}&#x27;))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">for disk in &quot;${nvme_disks[@]}&quot;; do</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  # Find corresponding mounted partition</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  mount_path=$(mount | grep &quot;$disk&quot; | awk -F&#x27;[[:space:]]&#x27; &#x27;{print $3}&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  echo &quot;Apply Hadoop Storaget Type Label [SSD] to $disk ($mount_path)&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  curr_value=$(xmlstarlet sel -t -v &#x27;//configuration/property[name = &quot;dfs.data.dir&quot;]/value&#x27; $HDFS_CORE_SITE)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  echo &quot;current: $curr_value&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  new_value=$(echo $curr_value | sed &quot;s|$mount_path|[SSD]$mount_path|g&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  echo &quot;new: $new_value&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  xmlstarlet ed -L -u &quot;/configuration/property[name=&#x27;dfs.data.dir&#x27;]/value&quot; -v &quot;$new_value&quot; $HDFS_CORE_SITE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">done</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">systemctl restart hadoop-hdfs-datanode.service</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">exit 0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">EOF</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">chmod +x $SCRIPT_NAME</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sed -i &quot;s|null &amp;|null \&amp;\&amp; bash $SCRIPT_NAME &gt;&gt; \$STDOUT_LOG 2&gt;&gt; \$STDERR_LOG 0&lt;/dev/null \&amp;|&quot; /usr/share/aws/emr/node-provisioner/bin/provision-node</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">exit 0</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Once done, we can specify the following HBase configuration in the <em>hbase-site</em> in order to store our WALs files on SSD disks only.</p>
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">[</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;Classification&quot;: &quot;hbase-site&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;Properties&quot;: {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      &quot;hbase.wal.storage.policy&quot;: &quot;ALL_SSD&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>By doing this, WALs will be allocated and persisted on the HDFS using disks that have been labeled as SSD. To verify the setup, you can run the following command from the EMR master node that will display the corresponding allocations on the blocks on the HDFS for WALs.</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Describe block allocation for hbase root dir</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">hdfs fsck /user/hbase/WALs -files -blocks -locations</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Sample output</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">/user/hbase/WALs/ip-172-31-3-138.eu-west-1.compute.internal,16020,1674746296461/ip-172-31-3-138.eu-west-1.compute.internal%2C16020%2C1674746296461.1674746301597 135252162 bytes, replicated: replication=1, 1 block(s):  OK</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">0. BP-581531277-172.31.3.43-1674746228762:blk_1073741836_1012 len=135252162 Live_repl=1  [DatanodeInfoWithStorage[172.31.3.138:9866,DS-5ef6e227-738d-4cb5-9fc9-4d636744674d,SSD]]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">/user/hbase/WALs/ip-172-31-3-138.eu-west-1.compute.internal,16020,1674746296461/ip-172-31-3-138.eu-west-1.compute.internal%2C16020%2C1674746296461.1674746426864 135213883 bytes, replicated: replication=1, 1 block(s):  OK</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">0. BP-581531277-172.31.3.43-1674746228762:blk_1073742073_1255 len=135213883 Live_repl=1  [DatanodeInfoWithStorage[172.31.3.138:9866,DS-bf9acb8e-ad9f-4757-a8cb-59b9d1d0e659,SSD]]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Based on this example, you can create more complex scenarios depending on the volumes attached to the nodes.</p>
<p>HBase also provides another useful feature called <a href="https://issues.apache.org/jira/browse/HBASE-24289" target="_blank" rel="noopener noreferrer">Heterogeneous Storage for Date Tiered Compaction</a> to better handle cold and hot data separation. However, this feature has been introduced in the newer HBase 3.x versions only.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="summary">Summary<a href="#summary" class="hash-link" aria-label="Direct link to Summary" title="Direct link to Summary">​</a></h2>
<p>The following summarize a minimal set of configurations you can tune to improve the performance on an HDFS cluster.</p>
<div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">[</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;Classification&quot;: &quot;hbase-site&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;Properties&quot;: {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      &quot;hbase.regionserver.handler.count&quot;: &quot;120&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;Classification&quot;: &quot;hdfs-site&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;Properties&quot;: {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      &quot;dfs.namenode.handler.count&quot;: &quot;64&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      &quot;dfs.datanode.handler.count&quot;: &quot;48&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      &quot;dfs.client.hedged.read.threadpool.size&quot;: &quot;20&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      &quot;dfs.client.hedged.read.threshold.millis&quot;: &quot;100&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      &quot;dfs.client.read.shortcircuit&quot;: &quot;true&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      &quot;dfs.client.socket-timeout&quot;: &quot;60000&quot;, </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      &quot;dfs.domain.socket.path&quot;: &quot;/var/run/hadoop-hdfs/dn_socket&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/bestpractices/5 - Applications/Hbase/best_practice_hdfs.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/aws-open-data-analytics/docs/bestpractices/Applications/Hbase/best_practice"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Best Practices</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/aws-open-data-analytics/docs/bestpractices/Applications/Hbase/best_practice_s3"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Best Practice for Amazon S3</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#hdfs---name-node-memory" class="table-of-contents__link toc-highlight">HDFS - Name Node memory</a></li><li><a href="#hdfs---service-threads" class="table-of-contents__link toc-highlight">HDFS - Service Threads</a></li><li><a href="#hdfs---short-circuit-reads" class="table-of-contents__link toc-highlight">HDFS - Short Circuit Reads</a></li><li><a href="#hdfs---replication-factor" class="table-of-contents__link toc-highlight">HDFS - Replication Factor</a></li><li><a href="#hbase---hedged-reads" class="table-of-contents__link toc-highlight">HBase - Hedged Reads</a></li><li><a href="#hbase---tiered-storage" class="table-of-contents__link toc-highlight">HBase - Tiered Storage</a></li><li><a href="#summary" class="table-of-contents__link toc-highlight">Summary</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Get Involved</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://aws.github.io/aws-emr-best-practices/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Github<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Built with ❤️ at AWS  <br> © 2024 Amazon.com, Inc. or its affiliates. All Rights Reserved</div></div></div></footer></div>
</body>
</html>