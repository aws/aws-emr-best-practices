<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-bestpractices/Applications/Hbase/data_migration" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.1.0">
<title data-rh="true">Data Migration | AWS Open Data Analytics</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://aws.github.io/aws-emr-best-practices/img/AWS_logo_RGB.png"><meta data-rh="true" name="twitter:image" content="https://aws.github.io/aws-emr-best-practices/img/AWS_logo_RGB.png"><meta data-rh="true" property="og:url" content="https://aws.github.io/aws-emr-best-practices/docs/bestpractices/Applications/Hbase/data_migration"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Data Migration | AWS Open Data Analytics"><meta data-rh="true" name="description" content="This document describes possible migrations paths you can follow when migrating data from an existing HBase cluster (e.g. on premise, or self-managed cluster on EC2) to Amazon EMR."><meta data-rh="true" property="og:description" content="This document describes possible migrations paths you can follow when migrating data from an existing HBase cluster (e.g. on premise, or self-managed cluster on EC2) to Amazon EMR."><link data-rh="true" rel="icon" href="/aws-emr-best-practices/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://aws.github.io/aws-emr-best-practices/docs/bestpractices/Applications/Hbase/data_migration"><link data-rh="true" rel="alternate" href="https://aws.github.io/aws-emr-best-practices/docs/bestpractices/Applications/Hbase/data_migration" hreflang="en"><link data-rh="true" rel="alternate" href="https://aws.github.io/aws-emr-best-practices/docs/bestpractices/Applications/Hbase/data_migration" hreflang="x-default"><link rel="stylesheet" href="/aws-emr-best-practices/assets/css/styles.7a6c5961.css">
<script src="/aws-emr-best-practices/assets/js/runtime~main.c1201d9d.js" defer="defer"></script>
<script src="/aws-emr-best-practices/assets/js/main.c4280538.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/aws-emr-best-practices/"><div class="navbar__logo"><img src="/aws-emr-best-practices/img/logo.svg" alt="AWS Open Data Analytics" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/aws-emr-best-practices/img/logo.svg" alt="AWS Open Data Analytics" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">AWS Open Data Analytics</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/aws-emr-best-practices/docs/bestpractices/">Best Practices</a><a class="navbar__item navbar__link" href="/aws-emr-best-practices/docs/benchmarks/introduction">Benchmarks</a><a class="navbar__item navbar__link" href="/aws-emr-best-practices/docs/utilities/">Utilities</a><a class="navbar__item navbar__link" href="/aws-emr-best-practices/docs/migration/introduction">Migration</a></div><div class="navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input id="search_input_react" type="search" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/aws-emr-best-practices/docs/bestpractices/">EMR Best Practices Introduction</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/aws-emr-best-practices/docs/bestpractices/Cost Optimizations/Introduction">Cost Optimizations</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/aws-emr-best-practices/docs/bestpractices/Reliability/introduction">Reliability</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/aws-emr-best-practices/docs/bestpractices/Security/introduction">Security</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/aws-emr-best-practices/docs/bestpractices/Features/Managed Scaling/best_practices">Features</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/aws-emr-best-practices/docs/bestpractices/Applications/Hadoop/introduction">Applications</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Applications/Hadoop/introduction">Hadoop</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Applications/Hbase/introduction">Hbase</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Applications/Hbase/introduction">Introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Applications/Hbase/best_practice">Best Practices</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Applications/Hbase/best_practice_hdfs">Best Practice for HDFS</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Applications/Hbase/best_practice_s3">Best Practice for Amazon S3</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Applications/Hbase/data_integrity">Data Integrity / Disaster Recovery / High Availability</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Applications/Hbase/data_migration">Data Migration</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Applications/Hbase/management">Management</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Applications/Hbase/observability">Observability</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Applications/Hbase/performance_tests">Performance Tests</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Applications/Hbase/security">Security</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Applications/Hive/introduction">Hive</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Applications/Spark/introduction">Spark</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/aws-emr-best-practices/docs/bestpractices/Architecture/Adhoc/introduction">Architecture</a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/aws-emr-best-practices/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Applications</span><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Hbase</span><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Data Migration</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Data Migration</h1>
<p>This document describes possible migrations paths you can follow when migrating data from an existing HBase cluster (e.g. on premise, or self-managed cluster on EC2) to Amazon EMR.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="hbase-snapshots">HBase snapshots<a href="#hbase-snapshots" class="hash-link" aria-label="Direct link to HBase snapshots" title="Direct link to HBase snapshots">​</a></h2>
<p>This is the most straight forward approach that doesn&#x27;t require a complex setup and can easily be achieved using simple bash scripts. This approach is suitable if your data does not change frequently or when you can tolerate downtimes in your production systems to perform the data migration.</p>
<p>Below a list of steps that can be used to create a HBase Snapshot and transfer it to an Amazon S3 bucket. Please note that you can use the same approach to store snapshots on an HDFS cluster. If this is the case, replace the S3 target path in the following commands with the destination HDFS path (e.g. <code>hdfs://NN_TARGET:8020/user/hbase</code>) where you want to store the snapshots.</p>
<p><strong>Create a snapshot of a single HBase table</strong></p>
<p>When creating a snapshot, it’s good practice to also add an identifier in the snapshot name to have a reference date of when the snapshot was created. Before launching this command please replace the variable <code>TABLE_NAME</code> with the corresponding table you want to generate the snapshot for. If the table is in a namespace different from <code>default</code> use the following convention <code>NAMESPACE:TABLE_NAME</code>. From the SOURCE cluster submit the following commands:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">DATE=`date +&quot;%Y%m%d&quot;`</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">TABLE_NAME=&quot;YOUR_TABLE_NAME&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">hbase snapshot create -n &quot;${TABLE_NAME/:/_}-$DATE&quot; -t ${TABLE_NAME}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>To verify the snapshot just created, use the following command</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">hbase snapshot info -list-snapshots</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><strong>Copy the snapshot to an Amazon S3 bucket</strong></p>
<p><strong>Note</strong>
When migrating from an on premise cluster, make sure that you have Hadoop YARN installed in your cluster, as the commands rely on MR jobs to perform the copy to S3. Besides, you need to make sure that your Hadoop installation provides the <a href="https://hadoop.apache.org/docs/stable/hadoop-aws/tools/hadoop-aws/index.html" target="_blank" rel="noopener noreferrer">hadoop-aws</a> module that is required to communicate with Amazon S3.</p>
<p><strong>Note</strong> If you&#x27;re planning to use HBase with Amazon S3 as storage layer, you should use as <code>TARGET_BUCKET</code> the same S3 path that will be used as HBase S3 Root Directory while launching the EMR cluster. This minimize copies on S3 that are required when restoring the snapshots, thus reducing the restore time of your tables. To avoid any conflict during the snapshot copy, you should not start the EMR cluster (if using Amazon S3 as storage layer) before the end of the snapshot copy.</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">TARGET_BUCKET=&quot;s3://BUCKET/PREFIX/&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">hbase snapshot export -snapshot ${TABLE_NAME/:/_}-$DATE -copy-to $TARGET_BUCKET</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><strong>Restore Table when using Amazon S3 as storage layer for HBase</strong></p>
<p>If you followed the notes in the previous step, you&#x27;ll find the snapshot already available in HBase after launching the cluster.</p>
<p><strong>Note</strong> If your snapshot was created from a namespace different from the <code>default</code> one, make sure to pre create it, to avoid failures while restoring the snapshot. From the EMR master node:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Verify snapshot availability</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">HBASE_CMD=&quot;sudo -u hbase hbase&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$HBASE_CMD snapshot info -list-snapshots</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Review snapshot info and details</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">SNAPSHOT_NAME=&quot;YOUR_SNAPSHOT_NAME&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$HBASE_CMD snapshot info -snapshot $SNAPSHOT_NAME -size-in-bytes -files -stats -schema</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Optional - Create namespaces required by the snapshot</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">echo &quot;create_namespace \&quot;$NAMESPACE_NAME\&quot;&quot; | $HBASE_CMD shell</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Restore table from snapshot</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">echo &quot;restore_snapshot \&quot;$SNAPSHOT_NAME\&quot;&quot; | $HBASE_CMD shell</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><strong>Scripts</strong></p>
<p>The following scripts allows you to migrate and restore HBase tables an namespaces using the snapshot procedure previously described.</p>
<ul>
<li><a target="_blank" href="/aws-emr-best-practices/assets/files/hbase-snapshot-export-6c27b23a716f96e03afdf9707400bcc4.sh">Snapshot export</a> - Generate HBase snapshots for all the tables stored in all the namespaces, and copy them on an Amazon S3 bucket.</li>
<li><a target="_blank" href="/aws-emr-best-practices/assets/files/hbase-snapshot-import-243cdedf77d2add9a5bdf82850c3e121.sh">Snapshot import</a> - Restore all the snapshots stored in an Amazon S3 bucket.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="snapshots-with-incremental-export">Snapshots with Incremental Export<a href="#snapshots-with-incremental-export" class="hash-link" aria-label="Direct link to Snapshots with Incremental Export" title="Direct link to Snapshots with Incremental Export">​</a></h2>
<p>This approach might help in those situations where you want to migrate your data but at the same time you cannot tolerate much downtime in your production system. This approach helps to perform an initial bulk migration using the HBase snapshot procedure previously described, and then reconcile data received after the HBase snapshot generating incremental exports from the SOURCE table.</p>
<p>This approach works when the volume of ingested data is not high, as the procedure to reconcile the data in the DESTINATION cluster might require multiple iterations to synchronize the two clusters, along with the fact that might be error prone. The following highlights the overall migration procedure.</p>
<p>In the SOURCE cluster:</p>
<ul>
<li>
<p>Create a snapshot of the HBase table you want to migrate. Collect the epoch time when the snapshot was taken, as this will be used to determine new data ingested in the cluster.</p>
</li>
<li>
<p>Export the snapshot on Amazon S3 <code>org.apache.hadoop.hbase.snapshot.ExportSnapshot</code></p>
</li>
</ul>
<p>In the DESTINATION cluster:</p>
<ul>
<li>Import the snapshot in the cluster and restore the table</li>
</ul>
<p>In the SOURCE cluster:</p>
<ul>
<li>Generate an incremental export to S3 for data arrived in the cluster after taking the snapshot using the HBase utility <code>org.apache.hadoop.hbase.mapreduce.Export</code></li>
</ul>
<p>In the DESTINATION cluster:</p>
<ul>
<li>Restore the missing data in the destination cluster using the HBase utility <code>org.apache.hadoop.hbase.mapreduce.Import</code></li>
</ul>
<p><strong>Example Export Commands</strong></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">## Configurations</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">HBASE_CMD=&quot;sudo -u hbase hbase&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">BUCKET_NAME=&quot;YOUR_BUCKET_NAME&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">SNAPSHOT_PATH=&quot;s3://$BUCKET_NAME/hbase-snapshots/&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">TABLE_NAME=&quot;TestTable&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># ==============================================================================</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># (Simulate) Create TestTable with 1000 rows</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># ==============================================================================</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$HBASE_CMD pe --table=$TABLE_NAME --rows=1000 --nomapred sequentialWrite 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># ==============================================================================</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Take initial table snapshot and copy it to S3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># ==============================================================================</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">DATE=`date +&quot;%Y%m%d&quot;`</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">EPOCH_MS=`date +%s%N | cut -b1-13`</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">LABEL=&quot;$DATE-$EPOCH_MS&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># snapshot creation</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Note: HBase performs a FLUSH by default when creating a snapshot</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#       You can change this behaviour specifying the -s parameter</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$HBASE_CMD snapshot create -n &quot;${LABEL}-${TABLE_NAME}&quot; -t $TABLE_NAME</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># copy to S3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$HBASE_CMD org.apache.hadoop.hbase.snapshot.ExportSnapshot -snapshot &quot;${LABEL}-${TABLE_NAME}&quot; -copy-to $SNAPSHOT_PATH</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># ==============================================================================</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># (Simulate) Data mutations to simulate data arrived after taking the snapshot</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># ==============================================================================</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># overwrite the first 100 elements of the table</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$HBASE_CMD pe --rows=100 --nomapred sequentialWrite 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># check first 100 rows will have an higher timestamp compared to the 101 element</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">echo &quot;scan &#x27;$TABLE_NAME&#x27;, {LIMIT =&gt; 101}&quot; | $HBASE_CMD shell</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># ==============================================================================</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Generate incremental data export</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># ==============================================================================</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Retrieve the epoch time from the snapshot name that was previously created.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># This allow us to only export data modified since that moment in time.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$HBASE_CMD snapshot info -list-snapshots</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Incremental updates</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">LATEST_SNAPSHOT_EPOCH=&quot;$EPOCH_MS&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NEW_EPOCH_MS=`date +%s%N | cut -b1-13`</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">INCREMENTAL_PATH=&quot;s3://$BUCKET_NAME/hbase-delta/${TABLE_NAME}/${NEW_EPOCH_MS}&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$HBASE_CMD org.apache.hadoop.hbase.mapreduce.Export ${TABLE_NAME} $INCREMENTAL_PATH 1 $LATEST_SNAPSHOT_EPOCH</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><strong>Example Import Commands</strong></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">## Configurations</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">HBASE_CMD=&quot;sudo -u hbase hbase&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">BUCKET_NAME=&quot;YOUR_BUCKET_NAME&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">SNAPSHOT_PATH=&quot;s3://$BUCKET_NAME/hbase-snapshots/&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">HBASE_CONF=&quot;/etc/hbase/conf/hbase-site.xml&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">HBASE_ROOT=$(xmllint --xpath &quot;//configuration/property/*[text()=&#x27;hbase.rootdir&#x27;]/../value/text()&quot; $HBASE_CONF)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># ==============================================================================</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Import and Restore HBase snapshot</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># ==============================================================================</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">## List Snapshots on S3 and take note of the snapshot you want to restore</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$HBASE_CMD snapshot info -list-snapshots -remote-dir $SNAPSHOT_PATH</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">SNAPSHOT_NAME=&quot;SNAPSHOT_NAME&quot; # e.g. &quot;20220817-1660726018359-TestTable&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">## Copy snapshot on the cluster</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$HBASE_CMD snapshot export \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    -D hbase.rootdir=$SNAPSHOT_PATH \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    -snapshot $SNAPSHOT_NAME \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    -copy-to $HBASE_ROOT</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Restore initial snapshot</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">echo &quot;restore_snapshot &#x27;$SNAPSHOT_NAME&#x27;&quot; | $HBASE_CMD shell</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># ==============================================================================</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Replay incremental updates</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># ==============================================================================</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">TABLE_NAME=$(echo $SNAPSHOT_NAME | awk -F- &#x27;{print $3}&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">INCREMENTAL_PATH=&quot;s3://$BUCKET_NAME/hbase-delta/${TABLE_NAME}/${NEW_EPOCH_MS}&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$HBASE_CMD org.apache.hadoop.hbase.mapreduce.Import ${TABLE_NAME} ${INCREMENTAL_PATH}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="snapshots-with-hbase-replication">Snapshots with HBase Replication<a href="#snapshots-with-hbase-replication" class="hash-link" aria-label="Direct link to Snapshots with HBase Replication" title="Direct link to Snapshots with HBase Replication">​</a></h2>
<p>This approach describes how to migrate data using the <a href="https://hbase.apache.org/book.html#_cluster_replication" target="_blank" rel="noopener noreferrer">HBase cluster replication</a> feature that allows you to establish a peering between two (or more) HBase clusters so that they can replicate incoming data depending on how the peering was established.</p>
<p>In order to use this approach, a network connection between the SOURCE and DESTINATION cluster should be present. If you&#x27;re transferring data from an on premise cluster and you have large volumes of data to replicate, you might establish the connection between the two clusters using <a href="https://aws.amazon.com/directconnect/" target="_blank" rel="noopener noreferrer">AWS Direct Connect</a> or you can establish a VPN connection if this is a one time migration.</p>
<p>The below section highlight the overall procedure to establish the replication.</p>
<ul>
<li>In the SOURCE cluster, create a HBase peering with the DESTINATION cluster and then disable the peering so that data is accumulated in the HBase WALs.</li>
<li>In the SOURCE cluster, take a snapshot of the table you want to migrate and export it to S3.</li>
<li>In the DESTINATION cluster, import and restore the snapshot. This creates the metadata (table description) required for the replication and also restore the data present in the snapshot.</li>
<li>In the SOURCE cluster, re-enable the HBase peering with the DESTINATION cluster, so that data modified up to that moment will start to be replicated in the DESTINATION cluster.</li>
<li>Monitor the replication process from the HBase shell to verify the lag of replication before completely switch on the DESTINATION cluster, and shutdown the SOURCE cluster.</li>
</ul>
<p><strong>Create one-way peering: SOURCE → DESTINATION</strong></p>
<p><strong>Note</strong> The configuration for the replication should be enabled by default in HBase. To double check, verify <code>hbase.replication</code> is set to true in the <em>hbase-site.xml</em> in the SOURCE cluster.</p>
<p>To create the HBase peering, you need to know the DESTINATION ip or hostname of the node where the Zookeeper ensemble used by HBase is located. If the destination cluster is an Amazon EMR cluster this coincides with the EMR master node.</p>
<p>Once collected this information, from the SOURCE cluster execute the following commands to enable the peering with the destination cluster and start accumulating new data in the HBase WALs:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># The HBase command might be different in your Hadoop environment depending on</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># how HBase was installed and which user is used to properly launch the cli.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># In most installations, it&#x27;s sufficient to use the `hbase` command only.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">HBASE_CMD=&quot;sudo -u hbase hbase&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">MASTER_IP=&quot;**YOUR_MASTER_IP**&quot; # e.g. ip-xxx-xx-x-xx.eu-west-1.compute.internal</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">PEER_NAME=&quot;aws&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">TABLE_NAME=&quot;**YOUR_TABLE_NAME**&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">## Create peering with the destination cluster</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">echo &quot;add_peer &#x27;$PEER_NAME&#x27;, CLUSTER_KEY =&gt; &#x27;$MASTER_IP:2181:/hbase&#x27;&quot; | $HBASE_CMD shell</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">## List peers in the source cluster</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">echo &quot;list_peers&quot; | $HBASE_CMD shell</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">## Disable the peer just created, so that we can keep new data in the LOG (HBase WALs) until the snapshots are restored in the DESTINATION cluster</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">echo &quot;disable_peer &#x27;$PEER_NAME&#x27;&quot; | $HBASE_CMD shell</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">## enable replication for the tables to replicate</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">echo &quot;enable_table_replication &#x27;$TABLE_NAME&#x27;&quot; | $HBASE_CMD shell</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Now you can switch to the DESTINATION cluster and restore the initial snapshot taken for the table. Once the restore is complete, switch again on the SOURCE cluster and enable the HBase peering to start replicating new data ingested in the SOURCE cluster since the initial SNAPSHOT was taken.</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">HBASE_CMD=&quot;sudo -u hbase hbase&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">PEER_NAME=&quot;aws&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">echo &quot;enable_peer &#x27;$PEER_NAME&#x27;&quot; | $HBASE_CMD shell</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>To monitor the replication status you could use the hbase command <strong>status &#x27;replication&#x27;</strong> from the HBase shell on the SOURCE cluster.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="migrate-hbase-1x-to-hbase-2x">Migrate HBase 1.x to HBase 2.x<a href="#migrate-hbase-1x-to-hbase-2x" class="hash-link" aria-label="Direct link to Migrate HBase 1.x to HBase 2.x" title="Direct link to Migrate HBase 1.x to HBase 2.x">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="when-using-hdfs">When using HDFS<a href="#when-using-hdfs" class="hash-link" aria-label="Direct link to When using HDFS" title="Direct link to When using HDFS">​</a></h3>
<p>The migration path from HBase 1.x to HBase 2.x, can be accomplished using HBase snapshots if you&#x27;re using HDFS as storage layer. In this case you can take a snapshot on the HBase 1.x cluster and then restore it on the HBase 2.x one. Although it is highly recommended to migrate to the latest version of HBase 1.4.x before migrating to HBase 2.x, it is still possible to migrate from older version of the 1.x branch (1.0.x, 1.1.x, 1.2.x, etc).</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="when-using-amazon-s3">When using Amazon S3<a href="#when-using-amazon-s3" class="hash-link" aria-label="Direct link to When using Amazon S3" title="Direct link to When using Amazon S3">​</a></h3>
<p>If you&#x27;re using Amazon S3 as storage layer for HBase, you can directly migrate any EMR cluster using an HBase version &gt;= 1.x to an Amazon EMR release using HBase <code>&lt;= 2.2.x</code>.</p>
<p><strong>Note</strong> If you try to update to a more recent version of HBase (e.g. HBase 2.4.4 from HBase 1.x), the HBase master will fail to correctly start due to some breaking changes in the way HBase load the meta table information in newest releases. You might see a similar error in your HMaster logs:</p>
<div class="language-log codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-log codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Caused by: org.apache.hadoop.hbase.ipc.RemoteWithExtrasException(org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException): org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException: Column family table does not exist in region hbase:meta,,1.1588230740 in table &#x27;hbase:meta&#x27;, {TABLE_ATTRIBUTES =&gt; {IS_META =&gt; &#x27;true&#x27;, coprocessor$1 =&gt; &#x27;|org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint|536870911|&#x27;}}, {NAME =&gt; &#x27;info&#x27;, VERSIONS =&gt; &#x27;3&#x27;, KEEP_DELETED_CELLS =&gt; &#x27;FALSE&#x27;, DATA_BLOCK_ENCODING =&gt; &#x27;NONE&#x27;, TTL =&gt; &#x27;FOREVER&#x27;, MIN_VERSIONS =&gt; &#x27;0&#x27;, REPLICATION_SCOPE =&gt; &#x27;0&#x27;, BLOOMFILTER =&gt; &#x27;NONE&#x27;, IN_MEMORY =&gt; &#x27;true&#x27;, COMPRESSION =&gt; &#x27;NONE&#x27;, BLOCKCACHE =&gt; &#x27;true&#x27;, BLOCKSIZE =&gt; &#x27;8192&#x27;, METADATA =&gt; {&#x27;CACHE_DATA_IN_L1&#x27; =&gt; &#x27;true&#x27;}}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    at org.apache.hadoop.hbase.regionserver.HRegion.checkFamily(HRegion.java:8685)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:3125)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    at org.apache.hadoop.hbase.regionserver.HRegion.getScanner(HRegion.java:3110)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>In this case to migrate to the latest version, you can perform a two step migration:</p>
<ul>
<li>First, disable all your HBase tables in the Amazon EMR cluster using HBase 1.x. Once all the tables are disabled, terminate this cluster.</li>
<li>Launch a new Amazon EMR cluster using EMR 6.3.0 as release and wait for all the tables/regions to be assigned. Once completed, disable all the tables again and shutdown the cluster.</li>
<li>Finally, launch the latest EMR Version you want to use.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="summary">Summary<a href="#summary" class="hash-link" aria-label="Direct link to Summary" title="Direct link to Summary">​</a></h2>
<table><thead><tr><th>Approach</th><th>When to use?</th><th>Complexity</th></tr></thead><tbody><tr><td>Batch - HBase Snapshots</td><td>Data doesn&#x27;t change frequently or when you can tolerate high service downtime</td><td>Easy</td></tr><tr><td>Incremental - HBase Snapshots + Export</td><td>The data doesn&#x27;t change frequently and you have large tables</td><td>Medium</td></tr><tr><td>Online - HBase Snapshots + Replication</td><td>Data changes frequently and high service downtime cannot be tolerated</td><td>Advanced</td></tr></tbody></table></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/bestpractices/5 - Applications/Hbase/data_migration.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/aws-emr-best-practices/docs/bestpractices/Applications/Hbase/data_integrity"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Data Integrity / Disaster Recovery / High Availability</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/aws-emr-best-practices/docs/bestpractices/Applications/Hbase/management"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Management</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#hbase-snapshots" class="table-of-contents__link toc-highlight">HBase snapshots</a></li><li><a href="#snapshots-with-incremental-export" class="table-of-contents__link toc-highlight">Snapshots with Incremental Export</a></li><li><a href="#snapshots-with-hbase-replication" class="table-of-contents__link toc-highlight">Snapshots with HBase Replication</a></li><li><a href="#migrate-hbase-1x-to-hbase-2x" class="table-of-contents__link toc-highlight">Migrate HBase 1.x to HBase 2.x</a><ul><li><a href="#when-using-hdfs" class="table-of-contents__link toc-highlight">When using HDFS</a></li><li><a href="#when-using-amazon-s3" class="table-of-contents__link toc-highlight">When using Amazon S3</a></li></ul></li><li><a href="#summary" class="table-of-contents__link toc-highlight">Summary</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Get Involved</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/aws/aws-emr-best-practices/tree/main" target="_blank" rel="noopener noreferrer" class="footer__link-item">Github<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Built with ❤️ at AWS  <br> © 2024 Amazon.com, Inc. or its affiliates. All Rights Reserved</div></div></div></footer></div>
</body>
</html>