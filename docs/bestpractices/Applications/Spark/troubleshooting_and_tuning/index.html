<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-bestpractices/Applications/Spark/troubleshooting_and_tuning" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.1.0">
<title data-rh="true">5.2 - Spark troubleshooting and performance tuning | AWS Open Data Analytics</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://aws.github.io/aws-emr-best-practices/img/AWS_logo_RGB.png"><meta data-rh="true" name="twitter:image" content="https://aws.github.io/aws-emr-best-practices/img/AWS_logo_RGB.png"><meta data-rh="true" property="og:url" content="https://aws.github.io/aws-emr-best-practices/docs/bestpractices/Applications/Spark/troubleshooting_and_tuning"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="5.2 - Spark troubleshooting and performance tuning | AWS Open Data Analytics"><meta data-rh="true" name="description" content="5.2.1  -  Spark Structured Streaming applications have high Connection Create Rate to Amazon MSK"><meta data-rh="true" property="og:description" content="5.2.1  -  Spark Structured Streaming applications have high Connection Create Rate to Amazon MSK"><link data-rh="true" rel="icon" href="/aws-emr-best-practices/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://aws.github.io/aws-emr-best-practices/docs/bestpractices/Applications/Spark/troubleshooting_and_tuning"><link data-rh="true" rel="alternate" href="https://aws.github.io/aws-emr-best-practices/docs/bestpractices/Applications/Spark/troubleshooting_and_tuning" hreflang="en"><link data-rh="true" rel="alternate" href="https://aws.github.io/aws-emr-best-practices/docs/bestpractices/Applications/Spark/troubleshooting_and_tuning" hreflang="x-default"><link rel="stylesheet" href="/aws-emr-best-practices/assets/css/styles.7a6c5961.css">
<script src="/aws-emr-best-practices/assets/js/runtime~main.63780629.js" defer="defer"></script>
<script src="/aws-emr-best-practices/assets/js/main.f0a4b7fa.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/aws-emr-best-practices/"><div class="navbar__logo"><img src="/aws-emr-best-practices/img/logo.svg" alt="AWS Open Data Analytics" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/aws-emr-best-practices/img/logo.svg" alt="AWS Open Data Analytics" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">AWS Open Data Analytics</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/aws-emr-best-practices/docs/bestpractices/">Best Practices</a><a class="navbar__item navbar__link" href="/aws-emr-best-practices/docs/benchmarks/introduction">Benchmarks</a><a class="navbar__item navbar__link" href="/aws-emr-best-practices/docs/utilities/">Utilities</a></div><div class="navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input id="search_input_react" type="search" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/aws-emr-best-practices/docs/bestpractices/">EMR Best Practices Introduction</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/aws-emr-best-practices/docs/bestpractices/Cost Optimizations/Introduction">Cost Optimizations</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/aws-emr-best-practices/docs/bestpractices/Reliability/introduction">Reliability</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/aws-emr-best-practices/docs/bestpractices/Security/introduction">Security</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/aws-emr-best-practices/docs/bestpractices/Features/Managed Scaling/best_practices">Features</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/aws-emr-best-practices/docs/bestpractices/Applications/Hbase/introduction">Applications</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Applications/Hbase/introduction">Hbase</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Applications/Hive/introduction">Hive</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Applications/Spark/introduction">Spark</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Applications/Spark/introduction">Introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Applications/Spark/troubleshooting_and_tuning">Trouble Shooting and Perofrmance Tuning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Applications/Spark/best_practices">Best Practices</a></li></ul></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/aws-emr-best-practices/docs/bestpractices/Architecture/Adhoc/introduction">Architecture</a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/aws-emr-best-practices/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Applications</span><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Spark</span><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Trouble Shooting and Perofrmance Tuning</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>5.2 - Spark troubleshooting and performance tuning</h1>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="521-----spark-structured-streaming-applications-have-high-connection-create-rate-to-amazon-msk">5.2.1  -  Spark Structured Streaming applications have high Connection Create Rate to Amazon MSK<a href="#521-----spark-structured-streaming-applications-have-high-connection-create-rate-to-amazon-msk" class="hash-link" aria-label="Direct link to 5.2.1  -  Spark Structured Streaming applications have high Connection Create Rate to Amazon MSK" title="Direct link to 5.2.1  -  Spark Structured Streaming applications have high Connection Create Rate to Amazon MSK">​</a></h2>
<p><strong>Symptom</strong>: Amazon MSK cluster has high CPU usage and MSK metrics indicate high connection create rate to the cluster.</p>
<p><strong>Analysis</strong>: By default, Spark Structured Streaming Kafka connector has a 1:1 mapping relation of MSK TopicPartitions to Spark tasks. Between micro batches, Spark tries to (best effort) assign the same MSK TopicPartitions to the same executors which in turn reuses the Kafka consumers and connections.</p>
<p>Spark Structured Streaming Kafka connector has an option <code>minPartitions</code> which can divide large TopicPartitions to smaller pieces. When <code>minPartitions</code> is set to a value larger than the number of TopicPartitions,  Spark creates tasks based on <code>minPartitions</code> to increase parallelism (the number of Spark tasks will be approximately <code>minPartition</code>).</p>
<ul>
<li>As 1:1 mapping doesn&#x27;t exist anymore, Spark executors are randomly assigned to process any TopicPartition OffsetRanges. An executor processed TopicPartition X can be assigned to process TopicPartition Y in next micro batch.  A new Kafka consumer/connection needs to be created if Y is on another MSK broker.</li>
<li>One Spark executor can be assigned to process multiple Spark tasks with the same MSK TopicPartition on different OffsetRanges.  And in Spark 2.x, Kafka consumer cache is disabled when multiple tasks in the same executor read the same TopicPartitions .</li>
</ul>
<p>Setting <code>minPartitions</code> comes at a cost of initializing Kakfa consumers at each micro batch. This may impact performance especially when using SSL.</p>
<p>A test was run with following test environment:</p>
<p><strong>Kafka version 2.8.1</strong></p>
<ul>
<li>3 kafka.m5.xlarge instances</li>
<li>test kafka topic has 10 partitions</li>
<li>only SASL/SCRAM authentication enabled</li>
</ul>
<p><strong>EMR 5.36 (Spark 2.4.8)  cluster</strong></p>
<ul>
<li>30 core nodes - EC2 m5.4xlarge</li>
</ul>
<p>Spark Structured Streaming test application has 5 cores 5G memory for each executor.</p>
<p>Below figure shows the test result of different <code>minPartitions</code> values with MSK’s ConnectionCreationRate and CPUUser usages. As shown in the test result, higher ConnectionCreationRate is related to higher CPU usage.</p>
<p>Test1: 50 minPartitions 16:40-17:30<br>
<!-- -->Test2: 100 minPartitions 18:00-18:35<br>
<!-- -->Test3: 200 minPartitions 19:00-19:35<br>
<!-- -->Test4: no minPartitions 20:06 - 20:30</p>
<p><img loading="lazy" alt="ConnectionCreationRate" src="/aws-emr-best-practices/assets/images/spark-tt-1-2764119881a34635e803761b36ee0ba6.png" width="1545" height="603" class="img_ev3q"></p>
<p><strong>Recommendation</strong>:</p>
<ol>
<li>
<p>Upgrade to the latest EMR version (spark 3.x) to use Sparks <a href="https://spark.apache.org/docs/latest/structured-streaming-kafka-integration.html#consumer-caching" target="_blank" rel="noopener noreferrer">consumer pool cache</a> feature. This feature allows Spark to cache more than one Kafka consumer with same MSK TopicPartition at each executor, and reuse the consumers in later micro batches. This will allow you to set <code>minPartitions</code> while reduce the ConnectionCreationRate.</p>
</li>
<li>
<p>On EMR 5.x (Spark 2.x), only set min partitions when needed - for example, if you have data skew or if your stream is falling behind. Min partitions will allow you to increase parallelism and process records faster but at the expense of high connection rates and CPU.</p>
</li>
</ol>
<p>##<strong>5.2.2 - spark.driver.maxResultSize error on an EMR heterogeneous cluster but the driver is not collecting data</strong>
<strong>Symptom</strong>: Spark jobs fail from time to time and below error is seen in the log:</p>
<p><code>22/08/22 14:14:24 ERROR FileFormatWriter: Aborting job f6913a46-d2d8-46f0-a545-2d2ba938b113. org.apache.spark.SparkException: Job aborted due to stage failure: Total size of serialized results of 179502 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB) at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:2171)</code></p>
<p>By setting <code>spark.driver.maxResultSize</code> to 0(unlimited), the error is gone.  But the Spark job is not collecting data to driver, how can the result returning to driver exceed 1024MB?</p>
<p><strong>Analysis</strong>:  Each finished task sends a serialized <code>WriteTaskResult</code> object to driver. The object size is usually several kilobytes, e.g.</p>
<p><code>22/09/06 22:24:18 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 5192 bytes result sent to driver</code></p>
<p>From the log, we can see there are 179502 (or more) tasks. For such a number of tasks, the total result size can exceed 1024MB for serialized <code>WriteTaskResult</code> objects only.</p>
<p>The job is reading parquet files from S3 and the input folder has 3.5K parquet files with average size ~116MB per file. As default <code>spark.sql.files.maxPartitionBytes</code> is 128M, so approximately one file to one Spark task.  The job&#x27;s processing logic further splits one task to ~11 tasks. Total tasks should be 3.5K * 11 = 38.5K. But why there are 179502 (or more) tasks?</p>
<p>To find root cause, we need to understand how Spark SQL decides the max size of a partition for non-bucketed splittable files.</p>
<p>Spark2 is following below formula (Spark3 has a slightly different formula which is described later)</p>
<p><code>maxSplitBytes = Math.min(defaultMaxSplitBytes, Math.max(openCostInBytes, bytesPerCore))</code></p>
<p><code>maxSplitBytes</code> is the max bytes per partition.</p>
<p><code>defaultMaxSplitBytes</code> is from <code>spark.sql.files.maxPartitionBytes</code> whose default value is 128M.</p>
<p><code>openCostInBytes</code>  is from <code>spark.sql.files.openCostInBytes</code> whose default value is 4M.</p>
<p><code>bytesPerCore</code> = (Sum of all data file size + num of file * <code>openCostInBytes</code> ) / <code>defaultParallelism</code></p>
<p><code>defaultParallelism</code>’s default value is total number of virtual cores running the job.  It can also be set to a value by defining <code>spark.default.parallelism</code>.</p>
<p>When there are a large number of virtual cores allocated to the Spark job by Yarn, <code>maxSplitBytes</code> can be smaller than <code>defaultMaxSplitBytes</code>, i.e. more tasks will be created.  For this case, from Spark UI, we know total number of vcores is 15837, i.e. <code>defaultParallelism</code> is 15837
<img loading="lazy" alt="SparkUITotalCores" src="/aws-emr-best-practices/assets/images/spark-tt-2-8c7a2c6522fbef2dd6c58aa6fdadce9e.png" width="1553" height="205" class="img_ev3q"></p>
<p><code>bytesPerCore</code> = (116M * 3500 + 4M * 3500)/15837 = 26.5M</p>
<p><code>maxSplitBytes</code> = min(128M, max(4M, 26.5M)) = 26.5M.  So one 116M parquet file is split into 4~5 Spark tasks.  3.5K * 11 * 5 = 192.5K -- that&#x27;s why there were 179502 (or more) tasks.</p>
<p>Note that the vcore count is based on Yarn containers, not physical cores.  As Yarn’s default container allocation is based on available memory, this means there can be vcore over subscriptions in a heterogeneous EMR cluster.</p>
<p>For example, if we have a heterogeneous EMR cluster as below:</p>
<p>Core Node: c5.12xlarge(48cores/96GB) — Memory allocated to Yarn: 90112MB<br>
<!-- -->Task Node: r5.8xlarge(32cores/256GB) — Memory allocated to Yarn: 253952MB</p>
<p>The default EMR executor size is based on core node instance type. In this example, for c5.12xlarge, default executor size is 3 cores 4743M memory. Default <code>spark.yarn.executor.memoryOverheadFactor</code> is 0.1875.  A Yarn container has 3 cores, 4743MB*(1+0.1875)= 5632MB memory.</p>
<p>On c5.12xlarge, Yarn can allocate 16 conatainers with 48 vcores in total:<br>
<!-- -->90112MB/5632MB = 16 containers * 3 core = 48 vcores</p>
<p>While on r5.8xlarge, Yarn can allocate 45 containers with 135 vcores in total:<br>
<!-- -->253952MB/5632MB = 45 containers * 3 core = 135 vcores - 32cores = 103 vcore oversubscription</p>
<p><strong>Recommendation</strong>: When Spark reads splittable files, <code>maxSplitBytes</code> can be smaller than <code>spark.sql.files.maxPartitionBytes</code> if there are a big number of vcores allocated to the job.  Use the formula described here to set <code>spark.default.parallelism</code> value properly and have a reasonable <code>maxSplitBytes</code>.</p>
<p><strong>Spark 3</strong></p>
<p>Spark 3 provides more options to control<code>maxSplitBytes</code> as below</p>
<div class="language-scala codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-scala codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">  def maxSplitBytes(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      sparkSession: SparkSession,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      selectedPartitions: Seq[PartitionDirectory]): Long = {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    val defaultMaxSplitBytes = sparkSession.sessionState.conf.filesMaxPartitionBytes</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    val openCostInBytes = sparkSession.sessionState.conf.filesOpenCostInBytes</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    val minPartitionNum = sparkSession.sessionState.conf.filesMinPartitionNum</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      .getOrElse(sparkSession.leafNodeDefaultParallelism)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    val totalBytes = selectedPartitions.flatMap(_.files.map(_.getLen + openCostInBytes)).sum</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    val bytesPerCore = totalBytes / minPartitionNum</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Math.min(defaultMaxSplitBytes, Math.max(openCostInBytes, bytesPerCore))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><code>filesMinPartitionNum</code> is from <code>spark.sql.files.minPartitionNum</code>. It is the suggested (not guaranteed) minimum number of split file partitions. If not set, the default value is <code>spark.default.parallelism</code>.</p>
<p><code>leafNodeDefaultParallelism</code> is from <code>spark.sql.leafNodeDefaultParallelism</code>. It is the default parallelism of Spark SQL leaf nodes.</p>
<p>Setting either of the above two parameters has the same effect as <code>spark.default.parallelism</code> on <code>maxSplitBytes</code>.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/bestpractices/5 - Applications/Spark/troubleshooting_and_tuning.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/aws-emr-best-practices/docs/bestpractices/Applications/Spark/introduction"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Introduction</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/aws-emr-best-practices/docs/bestpractices/Applications/Spark/best_practices"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Best Practices</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#521-----spark-structured-streaming-applications-have-high-connection-create-rate-to-amazon-msk" class="table-of-contents__link toc-highlight">5.2.1  -  Spark Structured Streaming applications have high Connection Create Rate to Amazon MSK</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Get Involved</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/aws/aws-emr-best-practices/tree/main" target="_blank" rel="noopener noreferrer" class="footer__link-item">Github<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Built with ❤️ at AWS  <br> © 2024 Amazon.com, Inc. or its affiliates. All Rights Reserved</div></div></div></footer></div>
</body>
</html>