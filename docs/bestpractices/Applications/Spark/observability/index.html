<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-bestpractices/Applications/Spark/observability" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.5.2">
<title data-rh="true">Observability | AWS Open Data Analytics</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://aws.github.io/aws-emr-best-practices/img/AWS_logo_RGB.png"><meta data-rh="true" name="twitter:image" content="https://aws.github.io/aws-emr-best-practices/img/AWS_logo_RGB.png"><meta data-rh="true" property="og:url" content="https://aws.github.io/aws-emr-best-practices/docs/bestpractices/Applications/Spark/observability"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Observability | AWS Open Data Analytics"><meta data-rh="true" name="description" content="Debugging and monitoring"><meta data-rh="true" property="og:description" content="Debugging and monitoring"><link data-rh="true" rel="canonical" href="https://aws.github.io/aws-emr-best-practices/docs/bestpractices/Applications/Spark/observability"><link data-rh="true" rel="alternate" href="https://aws.github.io/aws-emr-best-practices/docs/bestpractices/Applications/Spark/observability" hreflang="en"><link data-rh="true" rel="alternate" href="https://aws.github.io/aws-emr-best-practices/docs/bestpractices/Applications/Spark/observability" hreflang="x-default"><link rel="preconnect" href="https://www.google-analytics.com">
<script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","G-MF59LKNSDN","auto"),ga("set","anonymizeIp",!0),ga("send","pageview")</script>
<script async src="https://www.google-analytics.com/analytics.js"></script><link rel="stylesheet" href="/aws-emr-best-practices/assets/css/styles.28ef5182.css">
<script src="/aws-emr-best-practices/assets/js/runtime~main.6392da9a.js" defer="defer"></script>
<script src="/aws-emr-best-practices/assets/js/main.9ad7564d.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/aws-emr-best-practices/"><b class="navbar__title text--truncate">AWS Open Data Analytics</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/aws-emr-best-practices/docs/bestpractices/introduction">Best Practices</a><a class="navbar__item navbar__link" href="/aws-emr-best-practices/docs/benchmarks/introduction">Benchmarks</a><a class="navbar__item navbar__link" href="/aws-emr-best-practices/docs/migration/introduction">Migration</a><a class="navbar__item navbar__link" href="/aws-emr-best-practices/docs/utilities/introduction">Utilities</a></div><div class="navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input id="search_input_react" type="search" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/aws-emr-best-practices/docs/bestpractices/introduction">EMR Best Practices</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/aws-emr-best-practices/docs/bestpractices/Applications/HBase/introduction">Applications</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Applications/HBase/introduction">HBase</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Applications/Hadoop/introduction">Hadoop</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Applications/Hive/introduction">Hive</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Applications/Spark/introduction">Spark</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Applications/Spark/introduction">Introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Applications/Spark/best_practices">Best Practices</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Applications/Spark/data_quality">Data Quality</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Applications/Spark/data_skew">Data Skew</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Applications/Spark/joins">Join Types</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Applications/Spark/observability">Observability</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Applications/Spark/performance">Performance</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Applications/Spark/thrift">Thrift Server</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Applications/Spark/troubleshooting">Troubleshooting</a></li></ul></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/aws-emr-best-practices/docs/bestpractices/Cost Optimizations/Introduction">Cost Optimizations</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/aws-emr-best-practices/docs/bestpractices/Features/EMRFS/aimd">Features</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/aws-emr-best-practices/docs/bestpractices/Observability/intro">Observability</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/aws-emr-best-practices/docs/bestpractices/Reliability/introduction">Reliability</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/aws-emr-best-practices/docs/bestpractices/Security/introduction">Security</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/aws-emr-best-practices/docs/bestpractices/Troubleshooting/Troubleshooting EMR">Troubleshooting</a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/aws-emr-best-practices/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Applications</span><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Spark</span><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Observability</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Observability</h1></header>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="debugging-and-monitoring">Debugging and monitoring<a href="#debugging-and-monitoring" class="hash-link" aria-label="Direct link to Debugging and monitoring" title="Direct link to Debugging and monitoring">​</a></h2>
<p>EMR provides several options to debug and monitor your Spark application. As you may have seen from some of the screenshots in this document, Spark UI is very helpful to determine your application performance and identify any potential bottlenecks. With regards to Spark UI, you have 3 options in Amazon EMR.</p>
<ol>
<li><strong>Spark Event UI</strong> This is the live user interface typically accessible on port 20888 (YARN Proxy). It shows the most up-to-date status of your jobs in real-time. You can go to this UI from Application Master URI in the Resource Manager UI. If you are using EMR Studio or EMR Managed Notebooks, you can navigate directly to Spark UI from your Jupyter notebook anytime after a Spark application is created using Livy. This UI is not accessible once the application finishes or if your cluster terminates.</li>
<li><strong>Spark History Server</strong> SHS runs on port 18080. It shows the history of your job runs. You may also see live application status but not in real time. SHS will persist beyond your application runtime but it becomes inaccessible when your EMR cluster is terminated.</li>
<li><strong>EMR Persistent UI</strong> Amazon EMR provides <a href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/app-history-spark-UI.html" target="_blank" rel="noopener noreferrer">Persistent User Interface for Spark</a>. This UI is accessible for up to 30 days after your application ends even if your cluster is terminated since the logs are stored off-cluster. This option is great for performing post-mortem analysis on your applications without spending on your cluster to stay active.</li>
</ol>
<p>Spark UI options are  also helpful to identify important metrics like shuffle reads/writes, input/output sizes, GC times, and also information like runtime Spark/Hadoop configurations, DAG, execution timeline etc. All these UIs will redirect you to live driver (cluster mode) or executor logs when you click on &quot;stderr&quot; or &quot;stdout&quot; from Tasks and Executors lists. When you encounter a task failure, if stderr of the executor does not provide adequate information, you can check the stdout logs. For additional details, see <a href="/aws-emr-best-practices/docs/benchmarks/Analyzing/read_spark_UI">Reading Spark UI</a></p>
<p><img decoding="async" loading="lazy" alt="BP - 31" src="/aws-emr-best-practices/assets/images/spark-bp-31-7576cd74ba8fad114ba8137e02b265e6.png" width="3083" height="1096" class="img_ev3q"></p>
<p>Apart from the UIs, you can also see application logs in S3 Log URI configured when you create your EMR cluster. Application Master (AM) logs can be found in <code>s3://LOG_PATH/CLUSTER_ID/containers/YARN_APP_ID/container_appID_attemptID_0001/</code>. AM container is the very first container launched in your Spark application. This is where your driver logs will be located if you ran your job in cluster deploy mode. If you ran your job in client deploy mode, driver logs are printed on to the console where you submitted your job which you can write to a file. If you used EMR Step API with client deploy mode, driver logs can be found in EMR Step&#x27;s stderr. Spark executor logs are found in the same S3 location. All containers than the first container belong to the executors. S3 logs are pushed every few minutes and are not live.</p>
<p><img decoding="async" loading="lazy" alt="BP - 32" src="/aws-emr-best-practices/assets/images/spark-bp-32-9a0b22dbd1c6e2b07a469cdc53926c37.png" width="728" height="457" class="img_ev3q"></p>
<p>If you have SSH access to the EC2 nodes of your EMR cluster, you can also see application master and executor logs stored in the local disk under /var/log/containers. You will only need to see the local logs if S3 logs are unavailable for some reason. Once the application finishes, the logs are aggregated to HDFS and are available for up to 48 hours based on the property <em><code>yarn.log-aggregation.retain-seconds</code></em>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="spark-observability-platforms">Spark Observability Platforms<a href="#spark-observability-platforms" class="hash-link" aria-label="Direct link to Spark Observability Platforms" title="Direct link to Spark Observability Platforms">​</a></h2>
<p>Spark JMX metrics will supply you with fine-grained details on resource usage. It goes beyond physical memory allocated and identifies the actual heap usage based on which you can tune your workloads and perform cost optimization. There are several ways to expose these JMX metrics. You can simply use a ConsoleSink which prints the metrics to console where you submit your job or CSVSink to write metrics to a file which you can use for data visualization. But these approaches are not tidy. There are more options as detailed <a href="https://spark.apache.org/docs/latest/monitoring.html" target="_blank" rel="noopener noreferrer">here</a>. You can choose an observability platform based on your requirements. Following are some example native options.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="amazon-managed-services-for-prometheus-and-grafana">Amazon Managed Services for Prometheus and Grafana<a href="#amazon-managed-services-for-prometheus-and-grafana" class="hash-link" aria-label="Direct link to Amazon Managed Services for Prometheus and Grafana" title="Direct link to Amazon Managed Services for Prometheus and Grafana">​</a></h3>
<p>AWS offers <a href="https://aws.amazon.com/prometheus/" target="_blank" rel="noopener noreferrer">Amazon Managed Prometheus (AMP)</a> which is a Prometheus-compatible monitoring and alerting service that makes it easy to monitor containerized applications and infrastructure at scale. <a href="https://aws.amazon.com/grafana/" target="_blank" rel="noopener noreferrer">Amazon Managed Grafana (AMG)</a> is a fully managed service for open source Grafana developed in collaboration with Grafana Labs. Grafana is a popular open source analytics platform that enables you to query, visualize, alert on and understand your metrics no matter where they are stored. You can find the <a href="https://aws.amazon.com/blogs/big-data/monitor-and-optimize-analytic-workloads-on-amazon-emr-with-prometheus-and-grafana/" target="_blank" rel="noopener noreferrer">deployment instructions</a> available to integrate Amazon EMR with OSS Prometheus and Grafana which can be extended to AMP and AMG as well. Additionally, Spark metrics can be collected using <a href="https://spark.apache.org/docs/latest/monitoring.html" target="_blank" rel="noopener noreferrer">PrometheusServlet</a> and <a href="https://github.com/prometheus/jmx_exporter" target="_blank" rel="noopener noreferrer">prometheus/jmx_exporter</a>. However, some bootstrapping is necessary for this integration.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="amazon-opensearch">Amazon Opensearch<a href="#amazon-opensearch" class="hash-link" aria-label="Direct link to Amazon Opensearch" title="Direct link to Amazon Opensearch">​</a></h3>
<p><a href="https://aws.amazon.com/blogs/opensource/introducing-opensearch/" target="_blank" rel="noopener noreferrer">Amazon Opensearch</a> is a community-driven open source fork of <a href="https://aws.amazon.com/blogs/opensource/stepping-up-for-a-truly-open-source-elasticsearch/" target="_blank" rel="noopener noreferrer">Elasticsearch and Kibana</a>. It is a popular service for log analytics. Logs can be indexed from S3 or local worker nodes to Amazon Opensearch either using AWS Opensearch SDK or Spark connector. These logs can then be visualized using Kibana To analyze JMX metrics and logs, you will need to develop a custom script for sinking the JMX metrics and importing logs.</p>
<p>Apart from native solutions, you can also use one of the AWS Partner solutions. Some of the popular choices are Splunk, Data Dog and Sumo Logic.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="monitor-cluster-health">Monitor cluster health<a href="#monitor-cluster-health" class="hash-link" aria-label="Direct link to Monitor cluster health" title="Direct link to Monitor cluster health">​</a></h2>
<p>Below are the recommended steps to monitor the health of your cluster:</p>
<ul>
<li>
<p><strong>Resource Manager UI</strong> Yarn is the resource manager of the EMR cluster. You can access the Resource Manage persistent UI to get a high level cluster metrics like Apps submitted, Apps Pending, Containers Running,Physical Mem Used % etc. You can also check Cluster node level metric, Scheduler Metrics and application level information and access the Resource Manager UI from the application tab of EMR cluster.</p>
</li>
<li>
<p><strong>NameNode UI</strong> NameNode is the HDFS master. You can access this UI to get information on HDFS status such as Configured Capacity, DFS Used, DFS Remaining, Live Nodes,Decommissioning Nodes. Datanode information tab tells the status of the datanode,datanode volume failures, snapshot and startup progress. The UI also gives utilities like metrics, log level information etc about the HDFS cluster. You can access the namenode UI from the application tab of EMR cluster</p>
</li>
<li>
<p><strong>AWS Management Console</strong> You can access cluster performance graphs from the Monitoring tab within your Amazon EMR console. The data presented falls into one of three categories: Cluster Status, Node Status, or Inputs/Outputs.</p>
</li>
</ul>
<p>Cloudwatch Metrics <a href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/UsingEMR_ViewingMetrics.html#UsingEMR_ViewingMetrics_MetricsReported" target="_blank" rel="noopener noreferrer">EMR cluster Metrics</a> can be monitored while key metrics for lookout are YarnavailableMemoryPercentage, IsIdle, ContainerPendingRatio, CoreNodesPending and CoreNodesRunning. You can create custom <a href="https://repost.aws/knowledge-center/emr-custom-metrics-cloudwatch" target="_blank" rel="noopener noreferrer">cloudwatch metrics dashboards</a> to get notified when certain conditions occurs.</p>
<ul>
<li>
<p>EMR metrics Dashboard can be created directly form the EMR monitoring tab or from the Cloudwatch by picking and choosing the EMR metric for the dashboard.</p>
</li>
<li>
<p>Set alarms by specifying metrics and conditions. Search the EMR cluster that you would like to create an alarm on then select the metric of EMR. Select the statistics and time period. Then select the condition for the alarm. Select the Alarm trigger, create or choose the SNS topic, subscribe to the SNS topic. You will get an email for the confirmation, confirm the subscription of the topic. Name the alarm and select create alarm.</p>
</li>
<li>
<p><a href="https://repost.aws/knowledge-center/emr-troubleshoot-failed-spark-jobs" target="_blank" rel="noopener noreferrer">Why did my Spark job in Amazon EMR fail?</a></p>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="monitor-structured-streaming-query-progress">Monitor Structured Streaming query progress<a href="#monitor-structured-streaming-query-progress" class="hash-link" aria-label="Direct link to Monitor Structured Streaming query progress" title="Direct link to Monitor Structured Streaming query progress">​</a></h2>
<p>To avoid Spark Structured Streaming jobs stuck for long time, try to monitor <code>QueryProgressEvent</code> per query id, take action if no <code>QueryProgressEvent</code> for the max time to process events (e.g. 60mins).</p>
<p>Below is an example code of registering a listener for  <code>QueryProgressEvent</code>  which will stop the query then more than 60 minutes no query progress event .</p>
<div class="language-scala codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-scala codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">import org.apache.log4j.Logger</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import org.apache.spark.sql.SparkSession</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import org.apache.spark.sql.functions._</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import org.apache.spark.sql.streaming.Trigger</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import org.apache.spark.sql.streaming.StreamingQueryListener</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import org.apache.spark.sql.streaming.StreamingQueryListener._</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import java.util.concurrent.ThreadFactory</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import java.util.concurrent.atomic.AtomicInteger</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import java.util.concurrent.{TimeUnit, Executors, ConcurrentHashMap, ScheduledFuture}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import scala.util.control.NonFatal</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">object QueryProgressListenerExample {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  lazy val logger: Logger = Logger.getLogger(QueryProgressListenerExample.getClass)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  private val queryTimerMap = new ConcurrentHashMap[String, ScheduledFuture[_]]()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  private val threadCounter = new AtomicInteger(0)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  private val threadFactory: ThreadFactory = new ThreadFactory {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    override def newThread(r: Runnable): Thread = {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      val t = new Thread(r)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      t.setDaemon(true) // Set the thread as a daemon thread</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      t.setName(s&quot;QueryProgressListenerThread-${threadCounter.getAndIncrement()}&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      t</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  private val myListener = new StreamingQueryListener {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    override def onQueryStarted(event: QueryStartedEvent): Unit = {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      startTimer(event.id.toString)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    override def onQueryProgress(event: QueryProgressEvent): Unit = {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      val queryId = event.progress.id.toString</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      val scheduledTask = queryTimerMap.get(queryId)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      if (scheduledTask != null) {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        logger.info(s&quot;Resetting the timeout for stream query ${event.progress.id}&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        resetTimer(queryId, scheduledTask)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    override def onQueryTerminated(event: QueryTerminatedEvent): Unit = {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      cancelTimer(event.id.toString)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  private def startTimer(queryId: String): Unit = {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    val executor = Executors.newSingleThreadScheduledExecutor(threadFactory)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    val scheduledTask = executor.schedule(new Runnable {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      override def run(): Unit = {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        try {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          val query = spark.streams.get(queryId)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          logger.info(s&quot;Query $queryId timed out after 60 minutes. Stopping the query.&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          query.stop()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        } catch {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          case NonFatal(e) =&gt; logger.error(s&quot;Error stopping query $queryId: ${e.getMessage}&quot;, e)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      60, </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      TimeUnit.MINUTES)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    queryTimerMap.put(queryId, scheduledTask)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  private def resetTimer(queryId: String, scheduledTask: ScheduledFuture[_]): Unit = {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    scheduledTask.cancel(false)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    startTimer(queryId)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  private def cancelTimer(queryId: String): Unit = {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    val scheduledTask = queryTimerMap.remove(queryId)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    if (scheduledTask != null) {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      scheduledTask.cancel(true)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  private lazy val spark: SparkSession = SparkSession.builder()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .appName(&quot;QueryProgressListenerExample&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .master(&quot;local[*]&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .getOrCreate()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  // run `nc -lk 9999` in terminal first</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  def main(args: Array[String]): Unit = {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    spark.streams.addListener(myListener)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    // Create a streaming DataFrame</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    val lines = spark.readStream</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      .format(&quot;socket&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      .option(&quot;host&quot;, &quot;localhost&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      .option(&quot;port&quot;, 9999)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      .load()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      .select(expr(&quot;value as word&quot;))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    val query = lines</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      .writeStream</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      .outputMode(&quot;append&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      .format(&quot;console&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      .trigger(Trigger.ProcessingTime(&quot;15 seconds&quot;))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      .start()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    query.awaitTermination()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/bestpractices/Applications/Spark/observability.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/aws-emr-best-practices/docs/bestpractices/Applications/Spark/joins"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Join Types</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/aws-emr-best-practices/docs/bestpractices/Applications/Spark/performance"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Performance</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#debugging-and-monitoring" class="table-of-contents__link toc-highlight">Debugging and monitoring</a></li><li><a href="#spark-observability-platforms" class="table-of-contents__link toc-highlight">Spark Observability Platforms</a><ul><li><a href="#amazon-managed-services-for-prometheus-and-grafana" class="table-of-contents__link toc-highlight">Amazon Managed Services for Prometheus and Grafana</a></li><li><a href="#amazon-opensearch" class="table-of-contents__link toc-highlight">Amazon Opensearch</a></li></ul></li><li><a href="#monitor-cluster-health" class="table-of-contents__link toc-highlight">Monitor cluster health</a></li><li><a href="#monitor-structured-streaming-query-progress" class="table-of-contents__link toc-highlight">Monitor Structured Streaming query progress</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Contributing</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/aws/aws-emr-best-practices/tree/main" target="_blank" rel="noopener noreferrer" class="footer__link-item">Github<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Built with   ❤️ at AWS  <br> © 2025 Amazon.com, Inc. or its affiliates. All Rights Reserved</div></div></div></footer></div>
</body>
</html>