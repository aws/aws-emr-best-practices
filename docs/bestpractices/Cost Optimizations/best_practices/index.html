<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-bestpractices/Cost Optimizations/best_practices" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.1.0">
<title data-rh="true">Cost Optimizations | AWS Open Data Analytics</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://aws.github.io/aws-emr-best-practices/img/AWS_logo_RGB.png"><meta data-rh="true" name="twitter:image" content="https://aws.github.io/aws-emr-best-practices/img/AWS_logo_RGB.png"><meta data-rh="true" property="og:url" content="https://aws.github.io/aws-emr-best-practices/docs/bestpractices/Cost Optimizations/best_practices"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Cost Optimizations | AWS Open Data Analytics"><meta data-rh="true" name="description" content="Best Practices (BP) for running cost optimized workloads on EMR."><meta data-rh="true" property="og:description" content="Best Practices (BP) for running cost optimized workloads on EMR."><link data-rh="true" rel="icon" href="/aws-emr-best-practices/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://aws.github.io/aws-emr-best-practices/docs/bestpractices/Cost Optimizations/best_practices"><link data-rh="true" rel="alternate" href="https://aws.github.io/aws-emr-best-practices/docs/bestpractices/Cost Optimizations/best_practices" hreflang="en"><link data-rh="true" rel="alternate" href="https://aws.github.io/aws-emr-best-practices/docs/bestpractices/Cost Optimizations/best_practices" hreflang="x-default"><link rel="stylesheet" href="/aws-emr-best-practices/assets/css/styles.7a6c5961.css">
<script src="/aws-emr-best-practices/assets/js/runtime~main.199ae6fb.js" defer="defer"></script>
<script src="/aws-emr-best-practices/assets/js/main.3c3486c3.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/aws-emr-best-practices/"><div class="navbar__logo"><img src="/aws-emr-best-practices/img/logo.svg" alt="AWS Open Data Analytics" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/aws-emr-best-practices/img/logo.svg" alt="AWS Open Data Analytics" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">AWS Open Data Analytics</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/aws-emr-best-practices/docs/bestpractices/">Best Practices</a><a class="navbar__item navbar__link" href="/aws-emr-best-practices/docs/benchmarks/introduction">Benchmarks</a><a class="navbar__item navbar__link" href="/aws-emr-best-practices/docs/utilities/">Utilities</a><a class="navbar__item navbar__link" href="/aws-emr-best-practices/docs/migration/introduction">Migration</a></div><div class="navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input id="search_input_react" type="search" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/aws-emr-best-practices/docs/bestpractices/">EMR Best Practices Introduction</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/aws-emr-best-practices/docs/bestpractices/Cost Optimizations/Introduction">Cost Optimizations</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Cost Optimizations/Introduction">Introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/aws-emr-best-practices/docs/bestpractices/Cost Optimizations/best_practices">Best Practices</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/aws-emr-best-practices/docs/bestpractices/Reliability/introduction">Reliability</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/aws-emr-best-practices/docs/bestpractices/Security/introduction">Security</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/aws-emr-best-practices/docs/bestpractices/Features/Managed Scaling/best_practices">Features</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/aws-emr-best-practices/docs/bestpractices/Applications/Hbase/introduction">Applications</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/aws-emr-best-practices/docs/bestpractices/Architecture/Adhoc/introduction">Architecture</a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/aws-emr-best-practices/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Cost Optimizations</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Best Practices</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Cost Optimizations</h1>
<p>Best Practices (BP) for running cost optimized workloads on EMR.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="bp-11-use-amazon-s3-as-your-persistent-data-store">BP 1.1 Use Amazon S3 as your persistent data store<a href="#bp-11-use-amazon-s3-as-your-persistent-data-store" class="hash-link" aria-label="Direct link to BP 1.1 Use Amazon S3 as your persistent data store" title="Direct link to BP 1.1 Use Amazon S3 as your persistent data store">​</a></h2>
<p>As of Oct 1, 2021, Amazon S3 is 2.3 cents a GB/month for the first 50TB. This is $275 per TB/year which is a much lower cost than 3x replicated data in HDFS. With HDFS, you’ll need to provision EBS volumes. EBS is 10 cents a GB/month, which is <code>~</code>4x the cost of Amazon S3 or 12x if you include the need for 3x HDFS replication.</p>
<p>Using Amazon S3 as your persistent data store allows you to grow your storage infinitely, independent of your compute.  With on premise Hadoop systems, you would have to add nodes just to house your data which may not be helping your compute and only increase cost.  In addition, Amazon S3 also has different storage tiers for less frequently accessed data providing opportunity for additional cost savings.</p>
<p>EMR makes using Amazon S3 simple with EMR File System (EMRFS). EMRFS is an implementation of HDFS that all EMR clusters use for accessing data in Amazon S3.</p>
<p><strong>Note:</strong> HDFS is still available on the cluster if you need it and can be more performant compared to Amazon S3. HDFS on EMR uses EBS local block store which is faster than Amazon S3 object store. Some amounts of HDFS/EBS may be still be required. You may benefit from using HDFS for intermediate storage or need it to store application jars. However, HDFS is not recommended for persistent storage. Once a cluster is terminated, all HDFS data is lost.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="bp-12-compress-compact-and-convert-your-amazon-s3-objects">BP 1.2 Compress, compact and convert your Amazon S3 Objects<a href="#bp-12-compress-compact-and-convert-your-amazon-s3-objects" class="hash-link" aria-label="Direct link to BP 1.2 Compress, compact and convert your Amazon S3 Objects" title="Direct link to BP 1.2 Compress, compact and convert your Amazon S3 Objects">​</a></h2>
<p><strong>Compress</strong> - By compressing your data, you reduce the amount of storage needed for the data, and minimize the network traffic between S3 and the EMR nodes. When you compress your data, make sure to use a compression algorithm that allows files to be split or have each file be the optimal size for parallelization on your cluster. File formats such as Apache Parquet or Apache ORC provide compression by default. The following image shows the size difference between two file formats, Parquet (has compression enabled) and JSON (text format, no compression enabled). The Parquet dataset is almost five times smaller than the JSON dataset despite having the same data.</p>
<p><img loading="lazy" alt="BP - 1" src="/aws-emr-best-practices/assets/images/bp-1-2c7c6f136bfdabf22fb3ec6ec911922c.png" width="934" height="418" class="img_ev3q"></p>
<p><strong>Compact</strong> - Avoid small files. Generally, anything less than 128 MB. By having fewer files that are larger, you can reduce the amount of Amazon S3 LIST requests and also improve the job performance. To show the performance impact of having too many files, the following image shows a query executed over a dataset containing 50 files and a query over a dataset of the same size, but with 25,000 files.
The query that executed on 1 file is 3.6x faster despite the tables and records being the same.</p>
<p><img loading="lazy" alt="BP - 2" src="/aws-emr-best-practices/assets/images/bp-2-8a83aa16be742872863b4f51657015b1.png" width="1332" height="310" class="img_ev3q"></p>
<p><strong>Convert</strong> - Columnar file formats like Parquet and ORC can improve read performance. Columnar formats are ideal if most of your queries only select a subset of columns. For use cases where you primarily select all columns, but only select a subset of rows, choose a row optimized file format such as Apache Avro. The following image shows a performance comparison of a select count(<code>*</code>) query between Parquet and JSON (text) file formats.</p>
<p>The query that executed over parquet ran 74x faster despite being larger in size.</p>
<p><img loading="lazy" alt="BP - 3" src="/aws-emr-best-practices/assets/images/bp-3-5ac41dcecd80572067a290097d45fa81.png" width="1332" height="438" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="bp-13-partition-and-bucket-your-data-in-amazon-s3">BP 1.3 Partition and Bucket your data in Amazon S3<a href="#bp-13-partition-and-bucket-your-data-in-amazon-s3" class="hash-link" aria-label="Direct link to BP 1.3 Partition and Bucket your data in Amazon S3" title="Direct link to BP 1.3 Partition and Bucket your data in Amazon S3">​</a></h2>
<p>Partition your data in Amazon S3 to reduce the amount of data that needs to be processed. When your applications or users access the data with the partition key, it only retrieves the objects that are required. This reduces the amount of data scanned and the amount of processing required for your job to run. This results in lower cost.</p>
<p>For example, the following image shows two queries executed on two datasets of the same size. One dataset is partitioned, and the other dataset is not.</p>
<p><img loading="lazy" alt="BP - 4" src="/aws-emr-best-practices/assets/images/bp-4-f34a9ba7e0ad23ac948df7daf2aea9b4.png" width="696" height="610" class="img_ev3q"></p>
<p>The query over the partitioned data (s3logsjsonpartitioned) took 20 seconds to complete and it scanned 349 MB of data. The query over the non-partitioned data (s3logsjsonnopartition) took 2 minutes and 48 seconds to complete and it scanned 5.13 GB of data.</p>
<p>Bucketing is another strategy that breaks down your data into ranges in order to minimize the amount of data scanned. This makes your query more efficient and reduces your job run time. The range for a bucket is determined by the hash value of one or more columns in the dataset. These columns are referred to as <code>bucketing</code> or <code>clustered by</code> columns. A bucketed table can be created as in the below example:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">CREATE TABLE IF NOT EXISTS database1.table1 (</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">col1 INT,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">col2 STRING,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">col3 TIMESTAMP</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">CLUSTERED BY (col1)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">INTO 5 BUCKETS</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">STORED AS PARQUET</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">LOCATION ‘s3:///buckets_test/hive-clustered/’;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>In this example, the bucketing column (col1) is specified by the <code>CLUSTERED BY (col1)</code> clause, and the number of buckets (5) is specified by the <code>INTO 5 BUCKETS</code> clause.</p>
<p>Bucketing is similar to partitioning – in both cases, data is segregated and stored – but there are a few key differences. Partitioning is based on a column that is repeated in the dataset and involves grouping data by a particular value of the partition column. While bucketing organizes data by a range of values, mainly involving primary key or non-repeated values in a dataset. Bucketing should be considered when your partitions are not comparatively equal in size or you have data skew with your keys. Certain operations like map-side joins are more efficient in bucket tables vs non bucketed ones.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="bp-14-use-the-right-hardware-family-for-the-job-type">BP 1.4 Use the right hardware family for the job type<a href="#bp-14-use-the-right-hardware-family-for-the-job-type" class="hash-link" aria-label="Direct link to BP 1.4 Use the right hardware family for the job type" title="Direct link to BP 1.4 Use the right hardware family for the job type">​</a></h2>
<p>Most Amazon EMR clusters can run on general-purpose EC2 instance types/families such as m5.xlarge and m6g.xlarge. Compute-intensive clusters may benefit from running on high performance computing (HPC) instances, such as the compute-optimized instance family (C5). High memory-caching spark applications may benefit from running on high memory instances, such as the memory-optimized instance family (R5). Each of the different instance families have a different core<!-- -->:memory<!-- --> ratio so depending on your application characteristic, you should choose accordingly.</p>
<p>The master node does not have large computational requirements. For most clusters of 50 or fewer nodes, you can use a general-purpose instance type such as m5. However, the master node is responsible for running key services such as Resource manager, Namenode, Hiveserver2 as such, it’s recommended to use a larger instance such as 8xlarge+. With single node EMR cluster, the master node is a single point of failure.</p>
<p><img loading="lazy" alt="BP - 9" src="/aws-emr-best-practices/assets/images/bp-9-05b7c2d4c74b2541a1705fd7d9cfaa11.png" width="726" height="276" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="bp-15-use-instances-with-instance-store-for-jobs-that-require-high-disk-iops">BP 1.5 Use instances with instance store for jobs that require high disk IOPS<a href="#bp-15-use-instances-with-instance-store-for-jobs-that-require-high-disk-iops" class="hash-link" aria-label="Direct link to BP 1.5 Use instances with instance store for jobs that require high disk IOPS" title="Direct link to BP 1.5 Use instances with instance store for jobs that require high disk IOPS">​</a></h2>
<p>Use dense SSD storage instances for data-intensive workloads such as I3en or d3en. These instances provide Non-Volatile Memory Express (NVMe) SSD-backed instance storage optimized for low latency, very high random I/O performance, high sequential read throughput and provide high IOPS at a low cost. EMR workloads that heavily use HDFS or spend a lot of time writing spark shuffle data can benefit from these instances and see improved performance which reduces overall cost.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="bp-16-use-graviton2-instances">BP 1.6 Use Graviton2 instances<a href="#bp-16-use-graviton2-instances" class="hash-link" aria-label="Direct link to BP 1.6 Use Graviton2 instances" title="Direct link to BP 1.6 Use Graviton2 instances">​</a></h2>
<p>Amazon EMR supports Amazon EC2 graviton instances with EMR Versions 6.1.0, 5.31.0 and later. These instances are powered by AWS Graviton2 processors that are custom designed by AWS utilizing 64-bit ArmNeoverse cores to deliver the best price performance for cloud workloads running in Amazon EC2. On Graviton2 instances, Amazon EMR runtime for Apache Spark provides an additional cost savings of up to 30%, and improved performance of up to 15% relative to equivalent previous generation instances.</p>
<p>For example, when you compare m5.4xlarge vs m6g.4xlarge. The total cost (EC2+EMR) / hour is</p>
<table><thead><tr><th>Instance Type</th><th style="text-align:right">EC2 + EMR Cost</th></tr></thead><tbody><tr><td>m5.4xlarge:</td><td style="text-align:right">$0.960</td></tr><tr><td>m6g.4xlarge:</td><td style="text-align:right">$0.770</td></tr></tbody></table>
<p>This is a 19.8% reduction in cost for the same amount of compute - 16vCPU and 64Gib Memory</p>
<p>For more information, see [here] (<a href="https://aws.amazon.com/blogs/big-data/amazon-emr-now-provides-up-to-30-lower-cost-and-up-to-15-improved-performance-for-spark-workloads-on-graviton2-based-instances" target="_blank" rel="noopener noreferrer">https://aws.amazon.com/blogs/big-data/amazon-emr-now-provides-up-to-30-lower-cost-and-up-to-15-improved-performance-for-spark-workloads-on-graviton2-based-instances</a>)</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="bp-17-select-the-appropriate-pricing-model-for-your-use-case-and-node-type">BP 1.7 Select the appropriate pricing model for your use case and node type<a href="#bp-17-select-the-appropriate-pricing-model-for-your-use-case-and-node-type" class="hash-link" aria-label="Direct link to BP 1.7 Select the appropriate pricing model for your use case and node type" title="Direct link to BP 1.7 Select the appropriate pricing model for your use case and node type">​</a></h2>
<p>The following table is general  guideline for purchasing options depending on your application scenario.</p>
<table><thead><tr><th>Application scenario</th><th style="text-align:center">Master node purchasing option</th><th style="text-align:center">Core nodes purchasing option</th><th style="text-align:right">Task nodes purchasing option</th></tr></thead><tbody><tr><td>Long-running clusters and data warehouses</td><td style="text-align:center">On-Demand</td><td style="text-align:center">On-Demand or instance-fleet mix</td><td style="text-align:right">Spot or instance-fleet mix</td></tr><tr><td>Cost-driven workloads</td><td style="text-align:center">Spot</td><td style="text-align:center">Spot</td><td style="text-align:right">Spot</td></tr><tr><td>Data-critical workloads</td><td style="text-align:center">On-Demand</td><td style="text-align:center">On-Demand</td><td style="text-align:right">Spot or instance-fleet mix</td></tr><tr><td>Application testing</td><td style="text-align:center">Spot</td><td style="text-align:center">Spot</td><td style="text-align:right">Spot</td></tr></tbody></table>
<p>For clusters where you need a minimum compute at all times - e.g spark streaming, ad hoc clusters. Using reserved instances or saving plans is recommended.</p>
<p>For more information, see <a href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-instance-purchasing-options.html" target="_blank" rel="noopener noreferrer">here</a></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="bp-18-use-spot-instances">BP 1.8 Use spot instances<a href="#bp-18-use-spot-instances" class="hash-link" aria-label="Direct link to BP 1.8 Use spot instances" title="Direct link to BP 1.8 Use spot instances">​</a></h2>
<p>Spot instances are unused EC2 Capacity that is offered at up to a 90% discount (vs On-Demand pricing) and should be used when applicable. While EC2 can reclaim Spot capacity with a two-minute warning, less than 5% of workloads are interrupted. Due to the fault-tolerant nature of big data workloads on EMR, they can continue processing, even when interrupted. Running EMR on Spot Instances drastically reduces the cost of big data, allows for significantly higher compute capacity, and reduces the time to process big data sets.</p>
<p><img loading="lazy" alt="BP - 11" src="/aws-emr-best-practices/assets/images/bp-11-d04c958f1d28a3104cb6958d4212f081.png" width="1138" height="419" class="img_ev3q"></p>
<p>For more information, see the <a href="https://aws.github.io/aws-emr-best-practices/features/spot_usage/best_practices/" target="_blank" rel="noopener noreferrer">spot usage best practices section</a></p>
<p>Additionally,
AWS Big Data Blog: Best practices for running Apache Spark applications using Amazon EC2 Spot Instances with Amazon EMR, see <a href="https://aws.amazon.com/blogs/big-data/best-practices-for-running-apache-spark-applications-using-amazon-ec2-spot-instances-with-amazon-emr/" target="_blank" rel="noopener noreferrer">here</a></p>
<p>Amazon EMR Cluster configuration guidelines and best practices, see <a href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-instances-guidelines.html#emr-plan-spot-instances" target="_blank" rel="noopener noreferrer">here</a></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="bp-19-mix-on-demand-and-spot-instances">BP 1.9 Mix on-Demand and spot instances<a href="#bp-19-mix-on-demand-and-spot-instances" class="hash-link" aria-label="Direct link to BP 1.9 Mix on-Demand and spot instances" title="Direct link to BP 1.9 Mix on-Demand and spot instances">​</a></h2>
<p>Consider using a combination of Spot and On-Demand instances to lower cost and runtime.  Two examples where where this may be applicable are when:</p>
<ol>
<li>Cost is more important than the time to completion, but you cannot tolerate an entire cluster being terminated.</li>
</ol>
<ul>
<li>In this case, you can use Spot instances for the task nodes, and use On-Demand/Reserved instances for the master and core nodes. Even if all spot nodes are reclaimed, your cluster will still be accessible and tasks will be re-run on the remaining core nodes.</li>
</ul>
<ol start="2">
<li>You need to meet SLAs but are also considered about cost</li>
</ol>
<ul>
<li>In this case, you would provision enough on demand capacity to meet your SLAs and then use additional spot to bring down your average cost. If spot is not available, you’ll still have on demand nodes to meet your SLA. When spot is available, your cluster will have additional compute which reduce run time and lowers the total cost of your job.</li>
<li>For example:</li>
</ul>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">10 node cluster running for 14 hours </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Cost = 1.0 * 10 * 14 = $140</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Add 10 more nodes on Spot at 0.5$/node</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">20 node cluster running for 7 hours </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Cost = 1.0 * 10 * 7 = $70 = 0.5 * 10 * 7 = $35 Total $105</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">50 % less run-time ( 14→ 7) 25% less cost (140→ 105)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><img loading="lazy" alt="BP - 10" src="/aws-emr-best-practices/assets/images/bp-10-f13c32b62356b25b248574d0add58daa.png" width="1063" height="331" class="img_ev3q"></p>
<p>One consideration when mixing on demand and spot is if spot nodes are reclaimed, tasks or shuffle data that were on those spot nodes may have to be re executed on the remaining nodes. This reprocessing would increase the total run time of the job compared to running on only on demand.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="bp-110-use-emr-managed-scaling">BP 1.10 Use EMR managed scaling<a href="#bp-110-use-emr-managed-scaling" class="hash-link" aria-label="Direct link to BP 1.10 Use EMR managed scaling" title="Direct link to BP 1.10 Use EMR managed scaling">​</a></h2>
<p>With Amazon EMR versions 5.30.0 and later (except for Amazon EMR 6.0.0), you can enable EMR managed scaling. Managed scaling lets you automatically increase or decrease the number of instances or units in your cluster based on workload. EMR continuously evaluates cluster metrics to make scaling decisions that optimize your clusters for cost and speed improving overall cluster utilization. Managed scaling is available for clusters composed of either instance groups or instance fleets</p>
<p>This helps you reduce costs by running your EMR clusters with just the correct of amount of resources that your application needs. This feature is also useful for use cases where you have spikes in cluster utilization (i.e. a user submitting a job) and you want the cluster to automatically scale based on the requirements for that application.</p>
<p>Here’s an example of cluster without auto scaling. Since the size of the cluster is static, there are resources you are paying for but your job does not actually need.</p>
<p><img loading="lazy" alt="BP - 5" src="/aws-emr-best-practices/assets/images/bp-5-313deecd82a6968b367ed3ff17eee4b6.png" width="960" height="540" class="img_ev3q"></p>
<p>Here’s an example of cluster with auto scaling. The cluster capacity (blue dotted line) adjusts to the job demand reducing unused resources and cost.
<img loading="lazy" alt="BP - 6" src="/aws-emr-best-practices/assets/images/bp-6-af7444058ff0a863fac0ca99ef1d8388.png" width="1620" height="872" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="bp-111-right-size-application-containers">BP 1.11 Right size application containers<a href="#bp-111-right-size-application-containers" class="hash-link" aria-label="Direct link to BP 1.11 Right size application containers" title="Direct link to BP 1.11 Right size application containers">​</a></h2>
<p>By default, EMR will try to set YARN and Spark memory settings to best utilize the instances compute resources. This is important to maximize your cluster resources. Whether you are migrating jobs to EMR or writing a new application, It is recommended that you start with default EMR configuration.  If you need to modify the default configuration for your specific use case, It’s important to use all the available resources of the cluster - both CPU and Memory.</p>
<p>For example, if you had a cluster that is using m5.4xlarge instances for its data nodes, you’d have 16 vCPU and 64GB of memory.</p>
<p>EMR will automatically set <code>yarn.nodemanager.resource.cpu-vcores and yarn.nodemanager.resource.memory-mb</code> in <code>yarn-site.xml</code> to allocate how much of the instances resources can be used for YARN applications. In the m5.4xlarge case, this is 16vCPU and 57344 mb. When using custom configuration for your spark containers, you want to ensure that the memory and cores you allocate to your executor is a multiple of the total resources allocated to yarn. For example, if you set</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">spark.executor.memory 20,000M</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">spark.yarn.executor.memoryOverhead 10% (2,000M)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">spark.executor.cores 4</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Spark will only be able to allocate 2 executors on each node resulting in 57,344 - 44,000(22,000<code>*</code>2 = 13,344 of unallocated resources and 76.7% memory utilization</p>
<p>However, if <code>spark.executor.memory</code> was right sized to the available total <code>yarn.nodemanager.resource.memory-mb</code> you would get higher instance utilization. For example,</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">spark.executor.memory 12,000M</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">spark.yarn.executor.memoryOverhead 10% (1,200M)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">spark.executor.cores 4</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Spark will be able to allocate 4 executors on each node resulting in only 57,344 - 52,800(13,200 * 4) = 4,544 of unallocated resources and 92.0% memory utilization</p>
<p>For more information on Spark and YARN right sizing see <a href="https://aws.amazon.com/blogs/big-data/best-practices-for-successfully-managing-memory-for-apache-spark-applications-on-amazon-emr/" target="_blank" rel="noopener noreferrer">here</a></p>
<p>and <a href="https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-hadoop-task-config.html" target="_blank" rel="noopener noreferrer">here</a></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="bp-112-monitor-cluster-utilization">BP 1.12 Monitor cluster utilization<a href="#bp-112-monitor-cluster-utilization" class="hash-link" aria-label="Direct link to BP 1.12 Monitor cluster utilization" title="Direct link to BP 1.12 Monitor cluster utilization">​</a></h2>
<p>Monitoring cluster utilization is important for right sizing your cluster which can help reduces costs. To monitor cluster utilization, you can use EMR cloudwatch metrics, Ganglia (can be installed with EMR) or configure a 3rd party tool like Grafana and Prometheus.</p>
<p>Regardless of which tool you use, you’ll want to monitor cluster metrics such as available vCPU, Memory and disk utilization to determine if you’re right sized for your workload.  If some containers are constantly available, shrinking your cluster saves cost without decreasing performance because containers are sitting idle.</p>
<p>For example, If looking at Ganglia shows that either CPU or memory is 100% but the other resources are not being used significantly, then consider moving to another instance type that may provide better performance at a lower cost or reducing the total cluster size. For example,</p>
<ul>
<li>if CPU is 100%, and memory usage is less than 50% on R4 or M5 series instance types, then moving to C4 series instance type may be able to address the bottleneck on CPU.</li>
<li>If both CPU and memory usage is at 50%, reducing cluster capacity in half could give you the same performance at half the cost</li>
</ul>
<p><img loading="lazy" alt="BP - 7" src="/aws-emr-best-practices/assets/images/bp-7-9de6fd9baac7b564e90f45c988425a65.png" width="624" height="373" class="img_ev3q"></p>
<p>These recommendations are more applicable towards job scoped pipelines or transient clusters where the workload pattern is known or constant. If the cluster is long running or the workload pattern is not predictable, using managed scaling should be considered since it will attempt to rightsize the cluster automatically.</p>
<p>For more information on which cloudwatch metrics are available, see <a href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/UsingEMR_ViewingMetrics.html" target="_blank" rel="noopener noreferrer">here</a></p>
<p>For more information on the Grafana and Prometheus solution, see <a href="https://aws.amazon.com/blogs/big-data/monitor-and-optimize-analytic-workloads-on-amazon-emr-with-prometheus-and-grafana/" target="_blank" rel="noopener noreferrer">here</a></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="bp-113-monitor-and-decommission-idle-emr-cluster">BP 1.13 Monitor and decommission idle EMR cluster<a href="#bp-113-monitor-and-decommission-idle-emr-cluster" class="hash-link" aria-label="Direct link to BP 1.13 Monitor and decommission idle EMR cluster" title="Direct link to BP 1.13 Monitor and decommission idle EMR cluster">​</a></h2>
<p>Decommission Amazon EMR clusters that are no longer required to lower cost.  This can be achieved in two ways. You can use EMR’s automatic termination policy starting 5.30.0 and 6.1.0 or, by monitoring the <code>isIdle</code> metric in CloudWatch and terminating yourself.</p>
<p>With EMR’s automatic termination policy feature, EMR continuously samples key metrics associated with the workloads running on the clusters, and auto-terminates when the cluster is idle. For more information on when a cluster is considered idle and considerations, see <a href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-auto-termination-policy.html" target="_blank" rel="noopener noreferrer">here</a></p>
<p>With EMR’s <code>isIdle</code> CloudWatch metric, EMR will emit 1 if no tasks are running and no jobs are running, and emit 0 otherwise. This value is checked at five-minute intervals and a value of 1 indicates only that the cluster was idle when checked, not that it was idle for the entire five minutes.  You can set an alarm to fire when the cluster has been idle for a given period of time, such as thirty minutes.  Non-YARN based applications such as Presto, Trino, or HBase are not considered with <code>isIdle</code> metrics.</p>
<p>For a sample solution of this approach, see <a href="https://aws.amazon.com/blogs/big-data/optimize-amazon-emr-costs-with-idle-checks-and-automatic-resource-termination-using-advanced-amazon-cloudwatch-metrics-and-aws-lambda/" target="_blank" rel="noopener noreferrer">here</a></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="bp-114-use-the-latest-amazon-emr-version">BP 1.14 Use the latest Amazon EMR version<a href="#bp-114-use-the-latest-amazon-emr-version" class="hash-link" aria-label="Direct link to BP 1.14 Use the latest Amazon EMR version" title="Direct link to BP 1.14 Use the latest Amazon EMR version">​</a></h2>
<p>Use the latest EMR version and upgrade whenever possible. New EMR versions have performance improvements, cost savings, bug fixes stability improvements and new features.</p>
<p>For more information, see EMR Release Guide see <a href="https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-release-components.html" target="_blank" rel="noopener noreferrer">here</a></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="bp-115-using-transient-and-long-running-clusters">BP 1.15 Using transient and long-running clusters<a href="#bp-115-using-transient-and-long-running-clusters" class="hash-link" aria-label="Direct link to BP 1.15 Using transient and long-running clusters" title="Direct link to BP 1.15 Using transient and long-running clusters">​</a></h2>
<p>Amazon EMR supports both transient clusters and long running clusters and both should be considered depending on your use case and job type.
<img loading="lazy" alt="BP - 8" src="/aws-emr-best-practices/assets/images/bp-8-a50b532c43c6696e803c66c42a7620e7.png" width="1372" height="326" class="img_ev3q"></p>
<p>In general, transient clusters are good for job scoped pipelines. Clusters can be right-sized to meet the exact needs of your job. Using transient clusters reduces the blast radius across other jobs and makes it easier to upgrade clusters and restart jobs. Since transient clusters are shutdown after the job is run, you don’t need to worry about idle resources and managing many aspects of cluster life cycle, including replacing failed nodes, upgrades, patching, etc.</p>
<p>In general, long running clusters are good for short-running jobs, ad hoc queries and streaming applications. Long running clusters can also be considered to save costs and operations for multi tenanted data science and engineering jobs.</p>
<p>From a cost optimization standpoint,</p>
<ul>
<li>If using transient clusters, ensure your instances and containers are right sized so that you are not over provisioned. Use BP 1.12 to determine cluster utilization and if you’re able to lower your requested compute while still meeting your SLA.</li>
<li>If using long running clusters, ensure you’re using EMR Managed Scaling to scale up and down resources based off your jobs needs. It is also important to treat the cluster as a transient resources and have the automation in place to decommission and restart clusters.</li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/bestpractices/1 - Cost Optimizations/best_practices.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/aws-emr-best-practices/docs/bestpractices/Cost Optimizations/Introduction"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Introduction</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/aws-emr-best-practices/docs/bestpractices/Reliability/introduction"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Introduction</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#bp-11-use-amazon-s3-as-your-persistent-data-store" class="table-of-contents__link toc-highlight">BP 1.1 Use Amazon S3 as your persistent data store</a></li><li><a href="#bp-12-compress-compact-and-convert-your-amazon-s3-objects" class="table-of-contents__link toc-highlight">BP 1.2 Compress, compact and convert your Amazon S3 Objects</a></li><li><a href="#bp-13-partition-and-bucket-your-data-in-amazon-s3" class="table-of-contents__link toc-highlight">BP 1.3 Partition and Bucket your data in Amazon S3</a></li><li><a href="#bp-14-use-the-right-hardware-family-for-the-job-type" class="table-of-contents__link toc-highlight">BP 1.4 Use the right hardware family for the job type</a></li><li><a href="#bp-15-use-instances-with-instance-store-for-jobs-that-require-high-disk-iops" class="table-of-contents__link toc-highlight">BP 1.5 Use instances with instance store for jobs that require high disk IOPS</a></li><li><a href="#bp-16-use-graviton2-instances" class="table-of-contents__link toc-highlight">BP 1.6 Use Graviton2 instances</a></li><li><a href="#bp-17-select-the-appropriate-pricing-model-for-your-use-case-and-node-type" class="table-of-contents__link toc-highlight">BP 1.7 Select the appropriate pricing model for your use case and node type</a></li><li><a href="#bp-18-use-spot-instances" class="table-of-contents__link toc-highlight">BP 1.8 Use spot instances</a></li><li><a href="#bp-19-mix-on-demand-and-spot-instances" class="table-of-contents__link toc-highlight">BP 1.9 Mix on-Demand and spot instances</a></li><li><a href="#bp-110-use-emr-managed-scaling" class="table-of-contents__link toc-highlight">BP 1.10 Use EMR managed scaling</a></li><li><a href="#bp-111-right-size-application-containers" class="table-of-contents__link toc-highlight">BP 1.11 Right size application containers</a></li><li><a href="#bp-112-monitor-cluster-utilization" class="table-of-contents__link toc-highlight">BP 1.12 Monitor cluster utilization</a></li><li><a href="#bp-113-monitor-and-decommission-idle-emr-cluster" class="table-of-contents__link toc-highlight">BP 1.13 Monitor and decommission idle EMR cluster</a></li><li><a href="#bp-114-use-the-latest-amazon-emr-version" class="table-of-contents__link toc-highlight">BP 1.14 Use the latest Amazon EMR version</a></li><li><a href="#bp-115-using-transient-and-long-running-clusters" class="table-of-contents__link toc-highlight">BP 1.15 Using transient and long-running clusters</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Get Involved</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/aws/aws-emr-best-practices/tree/main" target="_blank" rel="noopener noreferrer" class="footer__link-item">Github<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Built with ❤️ at AWS  <br> © 2024 Amazon.com, Inc. or its affiliates. All Rights Reserved</div></div></div></footer></div>
</body>
</html>